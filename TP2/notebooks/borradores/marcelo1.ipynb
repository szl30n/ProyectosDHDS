{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "HMXPbEkA3ux8"
   },
   "source": [
    "# **Preparacion del ambiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22469,
     "status": "ok",
     "timestamp": 1653009532150,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "2OGnnvMLC10Y",
    "outputId": "9c71d710-211c-474f-ba09-01e0d0a2af40"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12380/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1936,
     "status": "ok",
     "timestamp": 1653009605775,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "lxTQ0hqxwBDO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "#!pip install plotly==5.7.0\n",
    "import plotly.express as px\n",
    "from numpy.ma.core import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1653009616350,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "3W8b-X55lUnt"
   },
   "outputs": [],
   "source": [
    "# agregamos código para que identifique más de un display en una celda\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuYSmKVC2J9H"
   },
   "source": [
    "# **Importación de los datos de properati**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5635,
     "status": "ok",
     "timestamp": 1653009633574,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "UO_Dclz3wGzh"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12380/68940271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#en jupyter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/properatti.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#leo el archivo de properati\n",
    "#en colab\n",
    "#csv_path =\"/content/drive/MyDrive/DS - Curso/Clases/Desafio 1/Data/properatti.csv\"\n",
    "#data = pd.read_csv(csv_path)\n",
    "\n",
    "#en jupyter\n",
    "data = pd.read_csv(\"../../../data/properatti.csv\", sep = \",\", low_memory=False) \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.state_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me quedo solo con AMBA\n",
    "data = data[(data[\"state_name\"]== 'Capital Federal') | (data[\"state_name\"]== 'Bs.As. G.B.A. Zona Sur') | (data[\"state_name\"]=='Bs.As. G.B.A. Zona Norte') | (data[\"state_name\"]== 'Bs.As. G.B.A. Zona Oeste')]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#me quedo solo con amba\n",
    "mask = data[\"state_name\"] == \"Capital Federal\"\n",
    "data_CABA = data[mask]\n",
    "data_CABA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFIOpuFp36sg"
   },
   "source": [
    "# **Exploracion y limpieza**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1651431198527,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "MyPrO9DIxdDC",
    "outputId": "c886fc0a-fd06-4051-9de0-20b1b8d171ba"
   },
   "outputs": [],
   "source": [
    "#analizo la columna state_name para ver la distribución y porcentaje de cada valor unique (frecuencia)\n",
    "percent = (100*data.state_name.value_counts())/data.shape[0]\n",
    "state_prop = pd.DataFrame({ 'state_name': data.state_name.value_counts(), 'percent': (100*data.state_name.value_counts())/data.shape[0], 'cumpercent': percent.cumsum()})\n",
    "state_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1651431199835,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "pmlOwB4bhb5V",
    "outputId": "46e8cdf7-6e27-4974-d6f6-383b79606cff"
   },
   "outputs": [],
   "source": [
    "#hago un describe de las columnas numéricas sin ninguna limpieza ni imputación para ver valores extremos, y estadísticas básicas\n",
    "columns = data.select_dtypes('number').columns\n",
    "data[columns].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1651431226305,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "hl3Bk8rdplAB",
    "outputId": "f1b454af-8f2c-4627-8ede-a6c58802730e"
   },
   "outputs": [],
   "source": [
    "#exploramos precios por state y place, para ver posibles valores de imputación\n",
    "round(data.pivot_table(index='state_name', columns='property_type',\n",
    "                    aggfunc={ 'price_usd_per_m2':'median'}),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1651431226737,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "9FVHKpZ6Na89",
    "outputId": "75fedf48-4859-4c1f-fb8e-ef6ebc642caf"
   },
   "outputs": [],
   "source": [
    "#exploramos precios por state y place, para ver posibles valores de imputación\n",
    "round(data.pivot_table(index=['state_name','place_name'], columns='property_type',\n",
    "                    aggfunc={ 'price_usd_per_m2':'median'}),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimino columnas que no use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2keep = ['property_type', 'state_name', 'place_name', 'place_with_parent_names','price_aprox_usd', 'surface_total_in_m2','surface_covered_in_m2',\n",
    "             'price_usd_per_m2', 'rooms', 'description', 'title', 'properati_url']\n",
    "data = data.loc[:, cols2keep]\n",
    "#print(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1651431193843,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "IB8BdiwM4f3Q",
    "outputId": "93a5cec5-dea5-45b2-9af9-4bb0ee65941e"
   },
   "outputs": [],
   "source": [
    "##  ¿Qué campos tienen valores nulos? y cual es su porcentaje en la columna\n",
    "cant_nulos_por_campo = data.apply(lambda x: x.isnull().sum(), axis=0)\n",
    "percent_nulos_por_campo = data.apply(lambda x: (100 * x.isnull().sum() / data.shape[0]).round(2), axis=0)\n",
    "summary_nulos_por_campo = pd.DataFrame({ 'cant': cant_nulos_por_campo, 'percent': percent_nulos_por_campo ,'tipo': data.dtypes})\n",
    "print(summary_nulos_por_campo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ln1f4wsg36Kq"
   },
   "source": [
    "# **Imputaciones**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "wipHmRxOD_Zo"
   },
   "source": [
    "## Habitaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1653010012836,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "VaP1XKWAD_Zo",
    "outputId": "034c1c61-89e5-4b44-fff3-d5a13279c38f"
   },
   "outputs": [],
   "source": [
    "totalVentas = data.state_name.notnull().sum()\n",
    "totalSinCuartos = data.rooms.isnull().sum()\n",
    "porcentajeSinCuartos = round( (totalVentas- totalSinCuartos) / totalVentas * 100, 2)\n",
    "print('Total Registros \\t\\t\\t', totalVentas )\n",
    "print('Total sin ambientes \\t\\t\\t', totalSinCuartos )\n",
    "print('Porcentaje sin ambientes \\t\\t', porcentajeSinCuartos, ' %' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 1728,
     "status": "ok",
     "timestamp": 1653010131020,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "2nuavK7SD_Zq",
    "outputId": "1b5f6b7e-f99a-40fa-8265-61db4f8fc7da"
   },
   "outputs": [],
   "source": [
    "data['title'] = data.title.str.upper()\n",
    "data['description'] = data.description.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reemplazo_dic = {\"UNO\":\"1\", \"DOS\":\"2\", \"TRES\":\"3\", \"CUATRO\":\"4\", \"CINCO\":\"5\", \"SEIS\":\"6\", \"SIETE\":\"7\", \"OCHO\":\"8\",\n",
    "             \"NUEVE\":\"9\", \"DIEZ\":\"10\", \"MONOAMBIENTE\":\"1 AMBIENTE\", \"MONOAMB\" : \"1 AMBIENTE\", \"UN\":\"1\", \"AMBIENTE DIVISIBLE\":\"1 AMBIENTE\",\n",
    "             \"MONO AMBIENTE\": \"1 AMBIENTE\",\"DORMITORIOS\": \"AMBIENTE\",\"DORMITORIO\": \"AMBIENTE\",\"HABITACIONES\": \"AMBIENTE\",\"HABITACION\": \"AMBIENTE\"}\n",
    "for key in reemplazo_dic.keys():\n",
    "    data.description = data.description.str.replace(key, reemplazo_dic[key], regex=False)\n",
    "\n",
    "for key in reemplazo_dic.keys():\n",
    "    data.title = data.title.str.replace(key, reemplazo_dic[key], regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlRooms = data[(data.rooms.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1531,
     "status": "ok",
     "timestamp": 1653010349239,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "_A_1RC1TD_Zs",
    "outputId": "d8b990cc-c92c-4163-9cf0-076ca023fd86"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms[\"description\"].str.extract(\"(\\d+) AMB\").astype(float)\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1653010725259,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "_egDtQ9LD_Zs",
    "outputId": "b97041b4-2fca-4cbc-9b75-8aa9ec9b3fe8"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.title.str.extract(\"(\\d+) AMB\").astype(float)\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1271,
     "status": "ok",
     "timestamp": 1653010729725,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "Y6pll96WD_Zs",
    "outputId": "21fb99fc-7883-4e23-d34d-d90d962bd310"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.description.str.extract(\"(\\d+) DORM\").astype(float) + 1\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1653010732943,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "0kCRalQoD_Zs",
    "outputId": "f3828b00-b1d9-42c5-d24a-d58fb63b70e2"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.title.str.extract(\"(\\d+) DORM\").astype(float) + 1\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1653010734654,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "qFfiZbobD_Zs",
    "outputId": "cac8473a-593d-4ff1-bc22-cab1ede4708b"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.title.str.extract(\"(\\d+)AMB\").astype(float)\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1653010737196,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "ezWtM6q8D_Zs",
    "outputId": "78465143-0853-4788-d1ed-6838c1fed1f8"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.description.str.extract(\"(\\d+)AMB\").astype(float)\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1653010739150,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "jHUHSJeWD_Zt",
    "outputId": "ecfa42ce-bc1f-4066-9a32-3824408bdb4c"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.title.str.extract(\"(\\d+)DORM\").astype(float) + 1\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1653010741725,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "cc30-_wuD_Zt",
    "outputId": "2d009648-4e48-4544-ac2a-c2e56d2124e6"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.description.str.extract(\"(\\d+) DORM\").astype(float) + 1\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1653010744819,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "eSy4AA8pD_Zt",
    "outputId": "29ecb3c1-3d23-4ec6-f0d5-586373c44e4b"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.title.str.extract(\"(\\d+)HABITACIO\").astype(float) + 1\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64PchdGKD_Zt"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.title.str.extract(\"(\\d+) HABITACIO\").astype(float) + 1\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1653010753308,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "-lLn5Mt7D_Zt",
    "outputId": "d6ac5f76-b8f2-43df-a561-df316ec744ae"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'controlRooms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12380/1085966880.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontrolRooms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrooms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrolRooms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(\\d+)HABITACIO\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrolRooms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'controlRooms' is not defined"
     ]
    }
   ],
   "source": [
    "controlRooms.rooms = controlRooms.description.str.extract(\"(\\d+)HABITACIO\").astype(float) + 1\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1653010755820,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "gCE9ddiAD_Zt",
    "outputId": "b3c83a27-e28c-4760-8cac-6ff1c4facdd4"
   },
   "outputs": [],
   "source": [
    "controlRooms.rooms = controlRooms.description.str.extract(\"(\\d+) HABITACIO\").astype(float) + 1\n",
    "data.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1653010771267,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "pV3CkiZAD_Zt",
    "outputId": "409bd3bc-3042-4f8e-a900-68490397c48d"
   },
   "outputs": [],
   "source": [
    "controlRooms = data[(data.rooms.isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCEajwylD_Zu"
   },
   "source": [
    "Volvemos a controlar luego del proceso el grado de llenado de la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1653010837210,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "gqMQWxJuD_Zu",
    "outputId": "d25b76d1-4a37-4848-cf71-fd67b1f172d0"
   },
   "outputs": [],
   "source": [
    "totalVentas = data.state_name.notnull().sum()\n",
    "totalSinCuartos = data.rooms.isnull().sum()\n",
    "porcentajeSinCuartos = round( (totalVentas- totalSinCuartos) / totalVentas * 100, 2)\n",
    "print('Total Registros \\t\\t\\t', totalVentas )\n",
    "print('Total sin Ambientes \\t\\t\\t', totalSinCuartos )\n",
    "print('Porcentaje con ambientes \\t\\t', porcentajeSinCuartos, ' %' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chequeo de nuevo valores nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  ¿Qué campos tienen valores nulos? y cual es su porcentaje en la columna\n",
    "cant_nulos_por_campo = data.apply(lambda x: x.isnull().sum(), axis=0)\n",
    "percent_nulos_por_campo = data.apply(lambda x: (100 * x.isnull().sum() / data.shape[0]).round(2), axis=0)\n",
    "summary_nulos_por_campo = pd.DataFrame({ 'cant': cant_nulos_por_campo, 'percent': percent_nulos_por_campo ,'tipo': data.dtypes})\n",
    "print(summary_nulos_por_campo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "4WmXxMjC-Aol"
   },
   "source": [
    "## Elimino registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkpu640q-BQL",
    "outputId": "46b09656-d0ae-4ed1-8f99-b31eb8f73294"
   },
   "outputs": [],
   "source": [
    "## elimino duplicados \n",
    "data.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "7EbzNZe_DThP"
   },
   "source": [
    "## paso todo a minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19933,
     "status": "ok",
     "timestamp": 1651431246667,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "COr30JTr4gdR",
    "outputId": "d79905be-15d4-439b-f967-e3249f97b81f"
   },
   "outputs": [],
   "source": [
    "## pasar todas las columnas a minusculas\n",
    "data_lower = data.applymap(lambda x: x if np.isreal(x) else str(x).lower())\n",
    "# comparo los tipos de datos antes y después de pasar a minúsculas:\n",
    "print(data_lower.dtypes == data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "4hxbVZ5SDJmF"
   },
   "source": [
    "## Elimino outliers en price_usd_per_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651431246667,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "1cXVvSk94f0z",
    "outputId": "1f89b28d-1a82-44e2-be8f-b6b40fe68e41"
   },
   "outputs": [],
   "source": [
    "#búsqueda y reemplazo de outliers (de más de 2 std, 95%) por NaN en las columnas numéricas, en un solo paso\n",
    "df_sub = data.loc[:, 'price_usd_per_m2']\n",
    "lim = np.abs((df_sub - df_sub.mean()) / df_sub.std(ddof=0)) < 1.75\n",
    "data.loc[:, 'price_usd_per_m2'] = df_sub.where(lim, np.nan)\n",
    "#data.head(3)\n",
    "data.shape\n",
    "#data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_usd_per_m2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimino registros con valores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, how='any', subset=['property_type', 'state_name', 'place_name', 'price_aprox_usd', 'surface_total_in_m2','surface_covered_in_m2', 'rooms', 'price_usd_per_m2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ¿Qué campos tienen valores nulos? y cual es su porcentaje en la columna\n",
    "cant_nulos_por_campo = data.apply(lambda x: x.isnull().sum(), axis=0)\n",
    "percent_nulos_por_campo = data.apply(lambda x: (100 * x.isnull().sum() / data.shape[0]).round(2), axis=0)\n",
    "summary_nulos_por_campo = pd.DataFrame({ 'cant': cant_nulos_por_campo, 'percent': percent_nulos_por_campo ,'tipo': data.dtypes})\n",
    "print(summary_nulos_por_campo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion columnas dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iv79nG5uacrd"
   },
   "source": [
    "## Columnas dummies amenities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZJ2mBI0d3UN"
   },
   "outputs": [],
   "source": [
    "#fracciono la columna properti_url para sacar la nube de palabras mas repetidas\n",
    "import re\n",
    "patron_url = re.compile(pattern=\"_\", flags =re.IGNORECASE)\n",
    "lista_url = data[\"properati_url\"].apply(lambda x : patron_url.split(x))\n",
    "serie_palabras = pd.Series(np.hstack(lista_url))\n",
    "#serie_palabras.value_counts().head(20).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1653012657001,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "-fq0FwrK0FMR",
    "outputId": "78a2025c-5b32-4625-f200-82f2862afbf2"
   },
   "outputs": [],
   "source": [
    "serie_palabras.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk22xPJZa9pm"
   },
   "outputs": [],
   "source": [
    "# a partir de la nube de palabras selecciono las que son buenos adicionales\n",
    "adicionales = [\"garage\", \"balcon\", \"parrilla\", \"piscina\", \"terraza\", \"patio\", \"jardin\", \"quincho\", \"sum\", \"amenities\", \"baulera\", \"gimnasio\", \"subte-linea-d\", \"subte-linea-b\", \"subte-linea-a\", \"subte-linea-h\", \"subte-linea-e\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSivTSfQoiyj"
   },
   "outputs": [],
   "source": [
    "#elimino el primer elemento de lista_url para no tener el elemento con el http: etc\n",
    "for sublist in lista_url:\n",
    "  del sublist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1651431280039,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "ZmKJ4I_wlwxh",
    "outputId": "49a1a07b-36cd-4d86-9004-f168b551c1d1"
   },
   "outputs": [],
   "source": [
    "#lista_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xTQyApPl1_c"
   },
   "outputs": [],
   "source": [
    "#creo una función que compare la lista de palabras con la lista de listas\n",
    "#y me da como resultado una lista de listas de palabras true/false segun coincida o no \n",
    "def buscador_palabras(quebuscar, dondebuscar):\n",
    "  listadeextras = []\n",
    "  for listas in dondebuscar:\n",
    "    extras = []\n",
    "    for palabra in quebuscar:\n",
    "      if palabra in listas:\n",
    "        extras.append(True)\n",
    "      else:\n",
    "        extras.append(False)\n",
    "    listadeextras.append(extras)\n",
    "  #print(listadeextras)\n",
    "  return listadeextras     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1651431280900,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "QKvkph_HnmMP",
    "outputId": "694bb379-1473-4e3a-dc79-a905264d2952"
   },
   "outputs": [],
   "source": [
    "#aplico la funcion a mi lista \"adicionales\" y \"lista_url\"\n",
    "#chequeo que tenga la misma longitud de data\n",
    "resultado = buscador_palabras(adicionales,lista_url)\n",
    "len(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1651431280900,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "nE4L2iH5i1-4",
    "outputId": "90fcc17a-7268-4b64-b061-87b4f7263271"
   },
   "outputs": [],
   "source": [
    "#convierto resultado en dataframe, y renombro las columnas por la lista de palabras adicionales\n",
    "df = pd.DataFrame(resultado)\n",
    "df.columns = [\"garage\", \"balcon\", \"parrilla\", \"piscina\", \"terraza\", \"patio\", \"jardin\", \"quincho\", \"s.u.m.\", \"amenities\", \"baulera\", \"gimnasio\",\"subte-linea-d\", \"subte-linea-b\", \"subte-linea-a\", \"subte-linea-h\", \"subte-linea-e\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "DHZhUj4uxYJA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'state_name', 'place_name', 'place_with_parent_names',\n",
       "       'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
       "       'price_usd_per_m2', 'rooms', 'description', 'title', 'properati_url',\n",
       "       'garage', 'balcon', 'parrilla', 'piscina', 'terraza', 'patio', 'jardin',\n",
       "       'quincho', 's.u.m.', 'amenities', 'baulera', 'gimnasio',\n",
       "       'subte-linea-d', 'subte-linea-b', 'subte-linea-a', 'subte-linea-h',\n",
       "       'subte-linea-e'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uno el dataframe original con el nuevo generado de true/false\n",
    "#data = pd.merge(data,df,left_index=True, right_index=True)\n",
    "data = data.join(df)\n",
    "data.columns\n",
    "#antes me puso los dos indices como resultado del merge, y tuve que sacar la primera columna\n",
    "#data.drop(columns=data.columns[0], axis=1,inplace=True)\n",
    "#data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42717, 29)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f452ad15"
   },
   "source": [
    "## Dummies de State_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creé las dummies sin drop_first para poder hacer el join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sn = pd.get_dummies(data[\"state_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'state_name', 'place_name', 'place_with_parent_names',\n",
       "       'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
       "       'price_usd_per_m2', 'rooms', 'description', 'title', 'properati_url',\n",
       "       'garage', 'balcon', 'parrilla', 'piscina', 'terraza', 'patio', 'jardin',\n",
       "       'quincho', 's.u.m.', 'amenities', 'baulera', 'gimnasio',\n",
       "       'subte-linea-d', 'subte-linea-b', 'subte-linea-a', 'subte-linea-h',\n",
       "       'subte-linea-e', 'Bs.As. G.B.A. Zona Norte', 'Bs.As. G.B.A. Zona Oeste',\n",
       "       'Bs.As. G.B.A. Zona Sur', 'Capital Federal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(df_sn)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42717, 33)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies place_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creé las dummies sin drop_first para poder hacer el join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pn = pd.get_dummies(data[\"place_name\"], prefix=\"pn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'state_name', 'place_name', 'place_with_parent_names',\n",
       "       'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
       "       'price_usd_per_m2', 'rooms', 'description',\n",
       "       ...\n",
       "       'pn_Villa de Mayo', 'pn_Villa del Parque',\n",
       "       'pn_Village Golf & Tennis Country Club', 'pn_Virasoro Village',\n",
       "       'pn_Virrey del Pino', 'pn_Virreyes', 'pn_Wilde', 'pn_William Morris',\n",
       "       'pn_Zelaya', 'pn_coordenadas 34.255511'],\n",
       "      dtype='object', length=484)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(df_pn)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42717, 484)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimino las columnas no informativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(axis = 1, columns = ['description', 'title', 'properati_url'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6EgruhemL-O"
   },
   "source": [
    "# Exploracion post creacion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1651431277463,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "W9Bsh_e1TYbI",
    "outputId": "25463b0d-b8cf-4731-f75c-9e1966c1da65"
   },
   "outputs": [],
   "source": [
    "#EXPLORACION PRECIOS EN DOLARES POR M2, POR PROVINCIA\n",
    "round(data.pivot_table(index='state_name', columns='property_type',\n",
    "                    aggfunc={ 'price_usd_per_m2':'median'}),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ¿Qué campos tienen valores nulos? y cual es su porcentaje en la columna\n",
    "cant_nulos_por_campo = data.apply(lambda x: x.isnull().sum(), axis=0)\n",
    "percent_nulos_por_campo = data.apply(lambda x: (100 * x.isnull().sum() / data.shape[0]).round(2), axis=0)\n",
    "summary_nulos_por_campo = pd.DataFrame({ 'cant': cant_nulos_por_campo, 'percent': percent_nulos_por_campo ,'tipo': data.dtypes})\n",
    "print(summary_nulos_por_campo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXHPZXutaN0S"
   },
   "source": [
    "# **Exportación de resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VyjGCK_aMnH"
   },
   "outputs": [],
   "source": [
    "#creo un nuevo dataset de salida con los métodos aplicados\n",
    "# exportar a colab\n",
    "#df.to_csv(r'/content/drive/MyDrive/DSDH/TP1/properatti_nuevo.csv', index = False, header=True)\n",
    "#exportar local\n",
    "#data.to_csv(r'properatti_nuevo.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32391447"
   },
   "outputs": [],
   "source": [
    "# para exportar resultados\n",
    "data.to_csv(r'../../../data/properatti_tp2.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4918401f"
   },
   "outputs": [],
   "source": [
    "#usar el nuevo dataset desde el archivo\n",
    "data = pd.read_csv(\"../../../data/properatti_tp2.csv\", sep = \",\", low_memory=False) \n",
    "#data.head(3)\n",
    "data.shape\n",
    "\n",
    "# Esto no haría falta, ¿o sí? Porque ya estaba almacenado en la variable data, se sobreescribe con lo mismo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "uRPdpsNHCvvO"
   },
   "source": [
    "# **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "ec_ZZaiACvvP"
   },
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tard3cPMCvvP"
   },
   "outputs": [],
   "source": [
    "# Definimos parámetros globales para matplotlib.\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwKUBHpMCvvP"
   },
   "outputs": [],
   "source": [
    "# importamos el modelo lineal y algunas funciones para calcular la bondad de ajuste.\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3mYbwJ2CvvP"
   },
   "outputs": [],
   "source": [
    "# Seleccionamos la variable predictora y la objetivo.\n",
    "X = df[[features]]\n",
    "y = targets[target]\n",
    "\n",
    "# Importamos, Instanciamos, Fiteamos, etc..\n",
    "\n",
    "# Instanciamos el modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Fiteamos el modelo sobre los vectores X e y.\n",
    "model = lm.fit(X, y)\n",
    "#\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', model.intercept_)\n",
    "print ('RM=', ' ', model.coef_)\n",
    "# imprimos la metrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2_train=', ' ', model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTps1hBOCvvP"
   },
   "outputs": [],
   "source": [
    "# Generamos una función que resume los coeficientes, el intercepto y el R2\n",
    "# \"model\" = objeto con el modelo\n",
    "# \"X\" = matrix de variables independientes\n",
    "\n",
    "def sum_mod(model, X):\n",
    "    a = pd.DataFrame(model.coef_ , X.columns.values)\n",
    "    a = a.append(pd.DataFrame([model.intercept_, model.score(X, y)], index=['Intecept','R2']))\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGk0KyfLCvvQ"
   },
   "outputs": [],
   "source": [
    "# Graficamos el modelo\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando (una, dos, todas) las variables\")\n",
    "plt.ylabel(\"Valores reales \")\n",
    "plt.show()\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (\"¿Mejora?: \", mean_squared_error(y, predictions) < prevMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcTAPLkpCvvQ"
   },
   "source": [
    "## Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGhJ8EZdCvvQ"
   },
   "outputs": [],
   "source": [
    "# Importamos la api.\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# De manera análoga a la vista en el primer ejercicio, definimos el vector de variables con la primer variable RM.\n",
    "X = df[[features]]\n",
    "y = df[[target]]\n",
    "\n",
    "# Tenemos que agregar explícitamente a una constante:\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.plot(y,y, '-.', c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones\")\n",
    "plt.ylabel(\"Valores reales target\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos el MSE y un resumen del modelo\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZyZhrTXCvvQ"
   },
   "outputs": [],
   "source": [
    "#para CLMultiple\n",
    "# visualizamos la matriz de correlación en Seaborn usando a heatmap\n",
    "\n",
    "sns.heatmap(bikes.corr(), vmin=-1, vmax=1, center=0, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kEnZ3dwCvvQ"
   },
   "outputs": [],
   "source": [
    "#elegir entre modelos\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print ('MAE:', metrics.mean_absolute_error(true, pred))\n",
    "print ('MSE:', metrics.mean_squared_error(true, pred))\n",
    "print ('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))\n",
    "print ('R2:', metrics.r2_score(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBFo9QtbCvvR"
   },
   "outputs": [],
   "source": [
    "# Definimos una función que acepta una lista de features, hace el split entre train y test,\n",
    "# reservando un 25% de las observaciones para testeo, y devuelve la prueba RMSE.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_rmse(feature_cols):\n",
    "    X = bikes[feature_cols]\n",
    "    y = bikes.total\n",
    "    # Como estamos trabajando con observaciones ordenadas en el tiempo, ponemos\n",
    "    # shuffle=False para evitar data leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0O8JvaGCvvR"
   },
   "outputs": [],
   "source": [
    "# Chequeamos que las columnas son perfectamente dependientes.\n",
    "np.all(bikes.casual + bikes.registered == bikes.total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nP6rUc2JCvvR"
   },
   "source": [
    "## Compruebo los supuestos Gauss Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9zxDOc4CvvR"
   },
   "outputs": [],
   "source": [
    "#linearidad del modelo\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.api as sms\n",
    "sns.set_style('darkgrid')\n",
    "sns.mpl.rcParams['figure.figsize'] = (15.0, 9.0)\n",
    "\n",
    "def linearity_test(model, y):\n",
    "    '''\n",
    "    funcion para visualizar e identificar supuestos de linealidad sobre la regression lineal\n",
    "    \n",
    "    Args:\n",
    "    * model - fitted OLS model from statsmodels\n",
    "    * y - observed values\n",
    "    '''\n",
    "    fitted_vals = model.predict()\n",
    "    resids = model.resid\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    \n",
    "    sns.regplot(x=fitted_vals, y=y, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n",
    "    ax[0].set_title('Observados vs. Valores Predichos', fontsize=16)\n",
    "    ax[0].set(xlabel='Predichos', ylabel='Observados')\n",
    "\n",
    "    sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[1], line_kws={'color': 'red'})\n",
    "    ax[1].set_title('Residos vs. Valores Predichos', fontsize=16)\n",
    "    ax[1].set(xlabel='Predichos', ylabel='Residuos')\n",
    "    \n",
    "linearity_test(lin_reg, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWw9TyFrCvvR"
   },
   "outputs": [],
   "source": [
    "#media de los residuos\n",
    "lin_reg.resid.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_TmQS41CvvR"
   },
   "outputs": [],
   "source": [
    "#multicolinearidad uso IVF(inflación de varianza) muestra cuánto más grande es el error estándar, en comparación \n",
    "#con lo que sería si ese predictor no estuviera correlacionado con las otras características del modelo . \n",
    "#Si no se correlacionan características, todos los valores para VIF serán 1.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\n",
    "pd.DataFrame({'vif': vif[1:]}, index=X.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5_qVAOOCvvR"
   },
   "outputs": [],
   "source": [
    "#homocedasticidad\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.api as sms\n",
    "sns.set_style('darkgrid')\n",
    "sns.mpl.rcParams['figure.figsize'] = (15.0, 9.0)\n",
    "\n",
    "def homoscedasticity_test(model):\n",
    "    '''\n",
    "    Function for testing the homoscedasticity of residuals in a linear regression model.\n",
    "    It plots residuals and standardized residuals vs. fitted values and runs Breusch-Pagan and Goldfeld-Quandt tests.\n",
    "    \n",
    "    Args:\n",
    "    * model - fitted OLS model from statsmodels\n",
    "    '''\n",
    "    import numpy as np\n",
    "    fitted_vals = model.predict()\n",
    "    resids = model.resid\n",
    "    resids_standardized = model.get_influence().resid_studentized_internal\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "\n",
    "    sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n",
    "    ax[0].set_title('Residuals vs Fitted', fontsize=16)\n",
    "    ax[0].set(xlabel='Fitted Values', ylabel='Residuals')\n",
    "\n",
    "    sns.regplot(x=fitted_vals, y=np.sqrt(np.abs(resids_standardized)), lowess=True, ax=ax[1], line_kws={'color': 'red'})\n",
    "    ax[1].set_title('Scale-Location', fontsize=16)\n",
    "    ax[1].set(xlabel='Fitted Values', ylabel='sqrt(abs(Residuals))')\n",
    "\n",
    "    bp_test = pd.DataFrame(sms.het_breuschpagan(resids, model.model.exog), \n",
    "                           columns=['value'],\n",
    "                           index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n",
    "\n",
    "    gq_test = pd.DataFrame(sms.het_goldfeldquandt(resids, model.model.exog)[:-1],\n",
    "                           columns=['value'],\n",
    "                           index=['F statistic', 'p-value'])\n",
    "\n",
    "    print('\\n Breusch-Pagan test ----')\n",
    "    print(bp_test)\n",
    "    print('\\n Goldfeld-Quandt test ----')\n",
    "    print(gq_test)\n",
    "    print('\\n Residuals plots ----')\n",
    "\n",
    "homoscedasticity_test(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Df7kgBeHCvvS"
   },
   "outputs": [],
   "source": [
    "#autocorrelacion\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "acf = smt.graphics.plot_acf(lin_reg.resid, lags=40 , alpha=0.05)\n",
    "#acf.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYtoljvyCvvS"
   },
   "outputs": [],
   "source": [
    "#normalidad de los residuos\n",
    "from scipy import stats\n",
    "\n",
    "def normality_of_residuals_test(model):\n",
    "    '''\n",
    "    Function for drawing the normal QQ-plot of the residuals and running 4 statistical tests to \n",
    "    investigate the normality of residuals.\n",
    "    \n",
    "    Arg:\n",
    "    * model - fitted OLS models from statsmodels\n",
    "    '''\n",
    "    sm.ProbPlot(model.resid).qqplot(line='s');\n",
    "    plt.title('Q-Q plot');\n",
    "\n",
    "    jb = stats.jarque_bera(model.resid)\n",
    "    sw = stats.shapiro(model.resid)\n",
    "    ad = stats.anderson(model.resid, dist='norm')\n",
    "    ks = stats.kstest(model.resid, 'norm')\n",
    "    \n",
    "    print(f'Jarque-Bera test ---- statistic: {jb[0]:.4f}, p-value: {jb[1]}')\n",
    "    print(f'Shapiro-Wilk test ---- statistic: {sw[0]:.4f}, p-value: {sw[1]:.4f}')\n",
    "    print(f'Kolmogorov-Smirnov test ---- statistic: {ks.statistic:.4f}, p-value: {ks.pvalue:.4f}')\n",
    "    print(f'Anderson-Darling test ---- statistic: {ad.statistic:.4f}, 5% critical value: {ad.critical_values[2]:.4f}')\n",
    "    print('If the returned AD statistic is larger than the critical value, then for the 5% significance level, the null hypothesis that the data come from the Normal distribution should be rejected. ')\n",
    "    \n",
    "normality_of_residuals_test(lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "W1linq1NCvvS"
   },
   "source": [
    "## Variables dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNYhTGVnCvvS"
   },
   "outputs": [],
   "source": [
    "#pandas (drop_first para evitar la colinearidad perfecta)\n",
    "dummy = pd.get_dummies(df[column], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvXxLv1xCvvS"
   },
   "outputs": [],
   "source": [
    "#scikit onehotencoder\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "# fiteo y transformo la columna \"sex\"\n",
    "dummy_oneHot = onehot_encoder.fit_transform(df[['Sex']])\n",
    "# pongo un vector en un dataset.\n",
    "dummy_oneHot = pd.DataFrame(dummy_oneHot.toarray(),columns=df['Sex'].unique())\n",
    "dummy_oneHot.head()\n",
    "\n",
    "#con drop_first\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehot_encoder2 = OneHotEncoder(drop='first')\n",
    "# fiteo y transformo la columna \"sex\"\n",
    "dummy_oneHot_correct = onehot_encoder2.fit_transform(df[['Sex']])\n",
    "# pongo un vector en un dataset.\n",
    "dummy_oneHot_correct = pd.DataFrame(dummy_oneHot_correct.toarray())\n",
    "dummy_oneHot_correct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1UTv0-9CvvT"
   },
   "outputs": [],
   "source": [
    "#para variables categoricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(df['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o0t4azMCvvT"
   },
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-WsIM2-CvvT"
   },
   "outputs": [],
   "source": [
    "#metodo manual con mean y std\n",
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "plt.scatter(xs, ys, color='b')\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()\n",
    "\n",
    "xs = df[\"NOX\"]\n",
    "mean = np.mean(xs)\n",
    "std = np.std(xs)\n",
    "xs = [(x - mean) / std for x in xs]\n",
    "\n",
    "ys = df[\"TAX\"]\n",
    "mean = np.mean(ys)\n",
    "std = np.std(ys)\n",
    "ys = [(y - mean) / std for y in ys]\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX standardized\")\n",
    "plt.ylabel(\"TAX standardized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-kPHM--CvvT"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "xs = preprocessing.scale(df[\"NOX\"])\n",
    "ys = preprocessing.scale(df[\"TAX\"])\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX standardized\")\n",
    "plt.ylabel(\"TAX standardized\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1LJAlHsCvvT"
   },
   "outputs": [],
   "source": [
    "#manual min max\n",
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "plt.scatter(xs, ys, color='b')\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()\n",
    "\n",
    "xs = df[\"NOX\"]\n",
    "xmin = np.min(xs)\n",
    "xmax = np.max(xs)\n",
    "xs = [(x - xmin) / (xmax - xmin) for x in xs]\n",
    "\n",
    "ys = df[\"TAX\"]\n",
    "ymin = np.min(ys)\n",
    "ymax = np.max(ys)\n",
    "ys = [(y - ymin) / (ymax - ymin) for y in ys]\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX Min-Max Scaled\")\n",
    "plt.ylabel(\"TAX Min-Max Scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML77-t4VCvvU"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "xs = scaler.fit_transform(df[[\"NOX\"]])\n",
    "ys = scaler.fit_transform(df[[\"TAX\"]])\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX Min-Max Scaled\")\n",
    "plt.ylabel(\"TAX Min-Max Scaled\")\n",
    "plt.show()\n",
    "\n",
    "#o\n",
    "numericals = ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "\n",
    "X = data[numericals]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "std_numerical_data = scaler.transform(X)\n",
    "std_df = pd.DataFrame(std_numerical_data)\n",
    "std_df.columns = [i + '_std' for i in numericals]\n",
    "std_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axcWN-UFCvvU"
   },
   "source": [
    "## Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYJDnfN0CvvU"
   },
   "outputs": [],
   "source": [
    "rlm = linear_model.Ridge(alpha=0.5, normalize=True)\n",
    "\n",
    "# Ajustamos nuevamente, esta vez con regularizacion\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "\n",
    "ridge_model = rlm.fit(X, y)\n",
    "predictions = ridge_model.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "print (\"r^2:\", ridge_model.score(X, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnUiZ_KtCvvU"
   },
   "outputs": [],
   "source": [
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = ridge_model.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos#2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "\n",
    "print (\"r^2:\", ridge_model.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KCQH6mBCvvU"
   },
   "outputs": [],
   "source": [
    "# Veamos los coeficientes de la regresión Ridge:    \n",
    "ridge_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=0.5, normalize=True)\n",
    "\n",
    "# Ajustamos nuevamente, esta vez con regularizacion\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "lasso_model =lasso.fit(X, y)\n",
    "predictions = lasso_model.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "\n",
    "print (\"r^2:\", lasso_model.score(X, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = lasso_model.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos#2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "\n",
    "print (\"r^2:\", lasso_model.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos los coeficientes de la regresión Lasso:    \n",
    "lasso_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12380/2890942708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0melastic_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Ajustamos nuevamente, esta vez con regularizacion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvander\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "elastic_net = linear_model.ElasticNet(alpha=0.5, normalize=True)\n",
    "\n",
    "# Ajustamos nuevamente, esta vez con regularizacion\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "\n",
    "elastic_net.fit(X, y)\n",
    "predictions = elastic_net.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "\n",
    "print (\"r^2:\", elastic_net.score(X, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = elastic_net.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos#2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "print (\"r^2:\", elastic_net.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos los coeficientes de la regresión ElasticNet:\n",
    "elastic_net.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Optimizacion de lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciamos un modelo \n",
    "rlmcv = linear_model.RidgeCV(alphas=np.linspace(0.1,100, 1000), cv=3, normalize=True,scoring='r2')\n",
    "\n",
    "\n",
    "# Ajustamos nuevamente nuestro modelo, esta vez con RidgeCV\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "rlmcv.fit(X, y)\n",
    "predictions = rlmcv.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "plt.show()\n",
    "print (\"r^2:\", rlmcv.score(X, ys))\n",
    "print (\"alpha:\", rlmcv.alpha_)\n",
    "\n",
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = rlmcv.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos #2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "plt.show()\n",
    "print (\"r^2:\", rlmcv.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = linear_model.LassoCV(alphas=np.linspace(0.01,100, 1000), cv=3, normalize=True)\n",
    "xs, ys = generate_data()\n",
    "\n",
    "\n",
    "# Ajustamos nuevamente nuestro modelo, esta vez con LassoCV\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "lassocv.fit(X, y)\n",
    "predictions = lassocv.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "plt.show()\n",
    "print (\"r^2:\", lassocv.score(X, ys))\n",
    "print (\"alpha:\", lassocv.alpha_)\n",
    "\n",
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = lassocv.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos #2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "plt.show()\n",
    "print (\"r^2:\", lassocv.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "lm_lasso = linear_model.LassoCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10],\\\n",
    "                                        normalize = False, cv = 5) \n",
    "\n",
    "model_cv = lm_lasso.fit(X_train, y_train)\n",
    "\n",
    "model_cv.score(X_train, y_train)\n",
    "\n",
    "model_cv.coef_\n",
    "model_cv.intercept_\n",
    "model_cv.alpha_\n",
    "model_cv.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = model_cv.alpha_\n",
    "\n",
    "#L1_wt : 0, the fit is ridge regression. 1, the fit is the lasso \n",
    "\n",
    "no_reg_model = sm.OLS(y_train, X_train_sm)\n",
    "\n",
    "reg_model = no_reg_model.fit_regularized(alpha = best_alpha, L1_wt = 1)\n",
    "\n",
    "reg_model.params\n",
    "sns.scatterplot(x=reg_model.params, y=no_reg_model_params);\n",
    "\n",
    "reg_residuals = y_train - reg_model.fittedvalues\n",
    "\n",
    "linear_residuals = y_train - model.fittedvalues\n",
    "\n",
    "sns.scatterplot(x = reg_residuals, y = linear_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_prediction = reg_model.predict(X_test_sm)\n",
    "sm_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_lasso = linear_model.Lasso(alpha = best_alpha, fit_intercept=True, normalize=False)\n",
    "\n",
    "skl_lasso = skl_lasso.fit(X= X_train, y = y_train)\n",
    "\n",
    "skl_prediction = skl_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_residuals = y_test - skl_prediction\n",
    "\n",
    "sm_residuals = y_test - sm_prediction\n",
    "\n",
    "sns.scatterplot(x = skl_residuals, y = sm_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lasso_coef = np.insert(skl_lasso.coef_, 0, skl_lasso.intercept_)\n",
    "\n",
    "sns.scatterplot(x = lasso_coef, y = reg_model.params);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_measures.rmse(y_test, sm_prediction)\n",
    "eval_measures.meanabs(y_test, sm_prediction)\n",
    "metrics.r2_score(y_test, sm_prediction)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, skl_prediction))\n",
    "metrics.mean_absolute_error(y_test, skl_prediction)\n",
    "metrics.r2_score(y_test, skl_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "540Z4u8bCvvU"
   },
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "  \n",
    "random.seed(3)\n",
    "boston = datasets.load_boston()\n",
    "y = boston.target\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "lr = linear_model.LinearRegression()\n",
    "cv = KFold(5, shuffle=True)\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=cv, scoring='r2')\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y85Atb2v2Fkr"
   },
   "outputs": [],
   "source": [
    "model = linear_model.LassoCV().fit(X_train, y_train)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean(), zero_coefs=(model.coef_ == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxyy6cem2Fkx"
   },
   "outputs": [],
   "source": [
    "model = linear_model.LassoCV(normalize=True).fit(X, y)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
    "dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean(), zero_coefs=(model.coef_ == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZoL46Vn2Fk5"
   },
   "outputs": [],
   "source": [
    "model = linear_model.RidgeCV(normalize=True).fit(X, y)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
    "dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqLgk68nRWHk"
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/salary.dat', delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZnFcPkBqRWH2"
   },
   "outputs": [],
   "source": [
    "# Aplicar value_counts() a las series \"sx\", \"dg\", and \"rk\"\n",
    "\n",
    "categories = ['sx', 'rk', 'dg']\n",
    "\n",
    "for category in categories:\n",
    "    print(df[category].value_counts())\n",
    "    plt.bar(df[category].value_counts().index, df[category].value_counts().values, color='b',\\\n",
    "            alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiT-3pSFRWH9"
   },
   "outputs": [],
   "source": [
    "# Hacer unos violinplots a las series \"sx\", \"dg\", and \"rk\"\n",
    "\n",
    "for category in categories:\n",
    "    sns.violinplot(x=category, y='sl', data=df)\n",
    "    plt.show()\n",
    "\n",
    "# Repetir para \"dg\" y \"rk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Y186sjORWIC"
   },
   "outputs": [],
   "source": [
    "# Crear variables \"dummy\"\n",
    "\n",
    "for category in categories:\n",
    "    serie = df[category]\n",
    "    dummies = pd.get_dummies(serie, drop_first= True, prefix=category)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo usando solamente las variables cuantitativas y MCO\n",
    "\n",
    "X = df[['yr', 'yd']]\n",
    "y = df['sl']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=10)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model_1 = lm.fit(X_train, y_train)\n",
    "\n",
    "print('Score model_1:', model_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo usando solamente las variables cuantitativas aplicando regularización\n",
    "#¿Hace falta normalizar los features antes aplicar regularización en este caso? ¿Qué unidades tienen los features?\n",
    "\n",
    "lm_ridge = linear_model.RidgeCV(alphas=[0.1, 1, 10], normalize=True) \n",
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "\n",
    "model_2 = lm_ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Score model_2:', model_2.score(X_test, y_test))\n",
    "\n",
    "# ¿Mejoraron los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con MCO:\n",
    "\n",
    "X_all = df.drop(['sx', 'rk', 'dg', 'sl'], axis=1) \n",
    "\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y, test_size=0.35, random_state=10)\n",
    "\n",
    "model_3 = lm.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_3:', model_3.score(X_all_test, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con Ridge:\n",
    "\n",
    "lm_ridge = linear_model.RidgeCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10],\\\n",
    "                                        normalize=True, cv=3) \n",
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "\n",
    "model_4 = lm_ridge.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_4:', model_4.score(X_all_test, y_all_test))\n",
    "\n",
    "# ¿Mejoraron los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_ridge.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con Lasso:\n",
    "\n",
    "lm_lasso = linear_model.LassoCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10, 15, 25],\\\n",
    "                                        normalize=True, cv=3)\n",
    "\n",
    "model_5 = lm_lasso.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_5:', model_5.score(X_all_test, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_lasso.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De articulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LINEAR, RIDGE AND LASSO REGRESSION\n",
    "'''\n",
    "# importing requuired libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "# read test and train file\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print('\\n\\n---------DATA---------------\\n\\n')\n",
    "print(train.head())\n",
    "\n",
    "#splitting into training and test\n",
    "## try building model with the different features and compare the result.\n",
    "X = train.loc[:,['Outlet_Establishment_Year','Item_MRP']]\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,train.Item_Outlet_Sales,random_state=5)\n",
    "\n",
    "print('--------Trainig Linear Regression Model---------------')\n",
    "lreg = LinearRegression()\n",
    "#training the model\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "#predicting on cv\n",
    "pred = lreg.predict(x_cv)\n",
    "\n",
    "#calculating mse\n",
    "mse = np.mean((pred - y_cv)**2)\n",
    "print('\\nMean Sqaured Error = ',mse )\n",
    "\n",
    "#Let us take a look at the coefficients of this linear regression model.\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "\n",
    "coeff['Coefficient Estimate'] = Series(lreg.coef_)\n",
    "\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(lreg.score(x_cv,y_cv))\n",
    "\n",
    "print('\\n\\n---------Training Ridge Regression Model----------------')\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(x_train,y_train)\n",
    "pred1 = ridge.predict(x_cv)\n",
    "mse_1 = np.mean((pred1-y_cv)**2)\n",
    "\n",
    "print('\\n\\nMean Squared Error = ',mse_1)\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "coeff['Coefficient Estimate'] = Series(ridge.coef_)\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(ridge.score(x_cv,y_cv))\n",
    "\n",
    "\n",
    "print('\\n\\n---------Training Lasso Regression Model----------------')\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(x_train,y_train)\n",
    "pred2 = lasso.predict(x_cv)\n",
    "mse_2 = np.mean((pred2-y_cv)**2)\n",
    "\n",
    "print('\\n\\nMean Squared Error = ',mse_2)\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "coeff['Coefficient Estimate'] = Series(lasso.coef_)\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(lasso.score(x_cv,y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHEYbgoQCvvU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RJTCe2C6wQOm",
    "E6SOCe17pdUo",
    "7EbzNZe_DThP",
    "4hxbVZ5SDJmF",
    "5us__nDgReat",
    "YtKfSxatXg7r",
    "ZI-vZGEyS6ez",
    "UCBAtlE9xZRo",
    "tXHPZXutaN0S"
   ],
   "name": "Maela.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "07ad563c6c100133d3911bd17dbe454dbfdab792a93b10a38a834bd0d63e4aeb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
