{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# **1. Importación de *modules***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4780501a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "cdbfda03"
   },
   "source": [
    "# **2. Importación del dataset *properatti.csv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a7754818",
    "outputId": "05a09978-f855-4c68-c039-46d93fbde29b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121220, 26)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_csv(\"../data/properatti.csv\", sep = \",\", low_memory=False) \n",
    "#data.head(3)\n",
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Tratamiento de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## **3.1. Selección del subdataset AMBA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81150, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amba = ['Capital Federal', 'Bs.As. G.B.A. Zona Sur', 'Bs.As. G.B.A. Zona Norte', 'Bs.As. G.B.A. Zona Oeste']\n",
    "data_amba = data_raw[data_raw[\"state_name\"].isin(amba)]\n",
    "data_amba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## **3.2. Limpieza e imputaciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "9eafe596"
   },
   "source": [
    "### 3.2.1. Dropeo de columnas no informativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4211aba8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'state_name', 'place_name', 'place_with_parent_names',\n",
       "       'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
       "       'price_usd_per_m2', 'rooms', 'description', 'title', 'properati_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(81150, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols2keep = ['property_type', 'state_name', 'place_name','place_with_parent_names','price_aprox_usd', 'surface_total_in_m2','surface_covered_in_m2','price_usd_per_m2', 'rooms', 'description', 'title', 'properati_url']\n",
    "data_col_clean = data_amba.loc[:, cols2keep]\n",
    "data_col_clean.columns\n",
    "data_col_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### 3.2.2. Chequeo de valores nulos (no modifica datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "      <th>%</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_name</th>\n",
       "      <td>23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_with_parent_names</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <td>8656</td>\n",
       "      <td>10.67</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <td>22792</td>\n",
       "      <td>28.09</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <td>8505</td>\n",
       "      <td>10.48</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <td>29515</td>\n",
       "      <td>36.37</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>51211</td>\n",
       "      <td>63.11</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>properati_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          null      %     type\n",
       "property_type                0   0.00   object\n",
       "state_name                   0   0.00   object\n",
       "place_name                  23   0.03   object\n",
       "place_with_parent_names      0   0.00   object\n",
       "price_aprox_usd           8656  10.67  float64\n",
       "surface_total_in_m2      22792  28.09  float64\n",
       "surface_covered_in_m2     8505  10.48  float64\n",
       "price_usd_per_m2         29515  36.37  float64\n",
       "rooms                    51211  63.11  float64\n",
       "description                  1   0.00   object\n",
       "title                        0   0.00   object\n",
       "properati_url                0   0.00   object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_nulos_por_campo = data_col_clean.apply(lambda x: x.isnull().sum(), axis = 0)\n",
    "percent_nulos_por_campo = data_col_clean.apply(lambda x: (100 * x.isnull().sum() / data_col_clean.shape[0]).round(2), axis = 0)\n",
    "pd.DataFrame({'null': cant_nulos_por_campo, '%': percent_nulos_por_campo,'type': data_col_clean.dtypes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "wipHmRxOD_Zo"
   },
   "source": [
    "### 3.2.3. Imputación de la columna *rooms*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1653009986780,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "_gFyvCyrD_Zo",
    "outputId": "030eb50c-b338-4ff7-fd12-ccfebe2e4452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary rooms\n",
      "\n",
      "type: float64\n",
      "N total: 81150\n",
      "N null: 51211\n",
      "% null: 63.11%\n",
      "unique: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 22. 25. 32. nan]\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos el tipo y los valores (no modifica datasets)\n",
    "print(f'''summary rooms\n",
    "\n",
    "type: {data_col_clean.rooms.dtype}\n",
    "N total: {data_col_clean.shape[0]}\n",
    "N null: {data_col_clean.rooms.isnull().sum()}\n",
    "% null: {round((data_col_clean.rooms.isnull().sum() / data_col_clean.shape[0] * 100), 2)}%\n",
    "unique: {np.sort(data_col_clean['rooms'].unique())}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 1728,
     "status": "ok",
     "timestamp": 1653010131020,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "2nuavK7SD_Zq",
    "outputId": "1b5f6b7e-f99a-40fa-8265-61db4f8fc7da"
   },
   "outputs": [],
   "source": [
    "# Uniformamos la capitalización de las variables que se van a usar para imputar rooms\n",
    "data_col_clean['title'] = data_col_clean.title.str.upper()\n",
    "data_col_clean['description'] = data_col_clean.description.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cRpb5UXWD_Zr"
   },
   "outputs": [],
   "source": [
    "room_mapper = {\"UNO\": \"1\", \"UN\": \"1\", \"DOS\": \"2\", \"TRES\": \"3\", \"CUATRO\": \"4\", \"CINCO\": \"5\", \"SEIS\": \"6\", \"SIETE\": \"7\", \"OCHO\": \"8\",\n",
    "             \"NUEVE\": \"9\", \"DIEZ\": \"10\", \"MONO AMBIENTE\": \"1 AMBIENTE\", \"MONOAMBIENTE\": \"1 AMBIENTE\", \"MONOAMB\" : \"1 AMBIENTE\", \"AMBIENTE DIVISIBLE\": \"1 AMBIENTE\",\n",
    "             \"DORMITORIOS\": \"AMBIENTE\", \"DORMITORIO\": \"AMBIENTE\", \"HABITACIONES\": \"AMBIENTE\", \"HABITACION\": \"AMBIENTE\"}\n",
    "\n",
    "#for key in room_mapper.keys():\n",
    "#    data_col_clean[['title', 'description']].replace(key, room_mapper[key], inplace = True, regex = False)\n",
    "\n",
    "for key in room_mapper.keys():\n",
    "    data_col_clean.description = data_col_clean.description.str.replace(key, room_mapper[key], regex = False)\n",
    "    data_col_clean.title = data_col_clean.title.str.replace(key, room_mapper[key], regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Data/ProgramFiles/anaconda3/envs/dhds22/lib/python3.8/site-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "data_input = data_col_clean\n",
    "\n",
    "array_regex = [\"(\\d+)AMB\", \"(\\d+) AMB\", \"(\\d+)DORM\", \"(\\d+) DORM\", \"(\\d+)HABITACIO\", \"(\\d+) HABITACIO\"]\n",
    "\n",
    "for regex in array_regex:\n",
    "    controlRooms = data_input[(data_input.rooms.isnull())]\n",
    "    controlRooms.rooms = controlRooms.title.str.extract(regex).astype(float)\n",
    "    data_input.update(controlRooms)\n",
    "    controlRooms = data_input[(data_input.rooms.isnull())]\n",
    "    controlRooms.rooms = controlRooms.description.str.extract(regex).astype(float)\n",
    "    data_input.update(controlRooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1653010837210,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "gqMQWxJuD_Zu",
    "outputId": "d25b76d1-4a37-4848-cf71-fd67b1f172d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary rooms\n",
      "\n",
      "type: float64\n",
      "N total: 81150\n",
      "N null: 10685\n",
      "% null: 13.17%\n",
      "unique: [0.0000e+00 1.0000e+00 2.0000e+00 3.0000e+00 4.0000e+00 5.0000e+00\n",
      " 6.0000e+00 7.0000e+00 8.0000e+00 9.0000e+00 1.0000e+01 1.1000e+01\n",
      " 1.2000e+01 1.3000e+01 1.4000e+01 1.5000e+01 1.6000e+01 1.7000e+01\n",
      " 1.8000e+01 2.0000e+01 2.1000e+01 2.2000e+01 2.3000e+01 2.4000e+01\n",
      " 2.5000e+01 2.7000e+01 2.9000e+01 3.0000e+01 3.2000e+01 3.3000e+01\n",
      " 3.5000e+01 3.6000e+01 3.7000e+01 4.0000e+01 4.2000e+01 4.5000e+01\n",
      " 4.8000e+01 5.0000e+01 5.1000e+01 5.2000e+01 5.4000e+01 6.0000e+01\n",
      " 6.2000e+01 7.0000e+01 7.2000e+01 8.0000e+01 8.2000e+01 8.3000e+01\n",
      " 8.5000e+01 8.7000e+01 9.0000e+01 9.1000e+01 1.0000e+02 1.0300e+02\n",
      " 1.2500e+02 2.1000e+02 2.7200e+02 4.0300e+02 6.0200e+02 6.6200e+02\n",
      " 7.7200e+02 8.3100e+02 9.0200e+02 2.0000e+03 4.0000e+03 6.0030e+03\n",
      " 2.0173e+04 2.0174e+04 6.5003e+04 1.1200e+05        nan]\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos el tipo y los valores luego de la imputación (no modifica datasets)\n",
    "print(f'''summary rooms\n",
    "\n",
    "type: {data_input['rooms'].dtype}\n",
    "N total: {data_input.shape[0]}\n",
    "N null: {data_input['rooms'].isnull().sum()}\n",
    "% null: {round((data_input['rooms'].isnull().sum() / data_col_clean.shape[0] * 100), 2)}%\n",
    "unique: {np.sort(data_input['rooms'].unique())}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "2fa218dc"
   },
   "source": [
    "### 3.2.4. Dropeo de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "74e8b238",
    "outputId": "47355a10-cc3b-4b85-dd5d-cb74f58cac5c"
   },
   "outputs": [],
   "source": [
    "data_input.drop_duplicates(keep = \"first\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "e794c75e"
   },
   "source": [
    "### 3.2.5. Limpieza de *outliers* en *price_usd_per_m2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9612917b",
    "outputId": "1b0616eb-71c9-4436-cff6-a035adeed0ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81150, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#búsqueda y reemplazo de outliers (de más de 2 std, 95%) por NaN en las columnas numéricas, en un solo paso\n",
    "data_out = data_input\n",
    "df_sub = data_out.loc[:, 'price_usd_per_m2']\n",
    "lim = np.abs((df_sub - df_sub.mean()) / df_sub.std(ddof=0)) < 2\n",
    "data_out.loc[:, 'price_usd_per_m2'] = df_sub.where(lim, np.nan)\n",
    "data_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### 3.2.6. Dropeo de *NaNs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42717, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_na = data_out\n",
    "data_na.dropna(axis = 0, how = 'any', subset = ['property_type', 'state_name', 'place_name', 'price_aprox_usd', 'surface_total_in_m2','surface_covered_in_m2', 'rooms', 'price_usd_per_m2'], inplace = True)\n",
    "data_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "      <th>%</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_with_parent_names</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>properati_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         null    %     type\n",
       "property_type               0  0.0   object\n",
       "state_name                  0  0.0   object\n",
       "place_name                  0  0.0   object\n",
       "place_with_parent_names     0  0.0   object\n",
       "price_aprox_usd             0  0.0  float64\n",
       "surface_total_in_m2         0  0.0  float64\n",
       "surface_covered_in_m2       0  0.0  float64\n",
       "price_usd_per_m2            0  0.0  float64\n",
       "rooms                       0  0.0  float64\n",
       "description                 0  0.0   object\n",
       "title                       0  0.0   object\n",
       "properati_url               0  0.0   object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Último chequeo de que no hay nans en las columnas de trabajo (feature y targets)\n",
    "\n",
    "cant_nulos_por_campo = data_na.apply(lambda x: x.isnull().sum(), axis = 0)\n",
    "percent_nulos_por_campo = data_na.apply(lambda x: (100 * x.isnull().sum() / data_na.shape[0]).round(2), axis = 0)\n",
    "pd.DataFrame({'null': cant_nulos_por_campo, '%': percent_nulos_por_campo,'type': data_na.dtypes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## **3.3. Creacion de columnas *dummies***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "iv79nG5uacrd"
   },
   "source": [
    "### 3.3.1. *Amenities*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TZJ2mBI0d3UN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "venta                       42662\n",
       "departamento                27323\n",
       "garage                      21795\n",
       "lavadero                    19749\n",
       "balcon                      17206\n",
       "parrilla                    16518\n",
       "piscina                     14135\n",
       "luminoso                    14032\n",
       "suite                       13137\n",
       "casa                        12777\n",
       "toilette                    11959\n",
       "placard                     10993\n",
       "terraza                     10784\n",
       "vestidor                     8882\n",
       "jardin                       7775\n",
       "patio                        6598\n",
       "dependencias                 6451\n",
       "sum                          5961\n",
       "aire-acondicionado           5700\n",
       "baulera                      5494\n",
       "amenities                    5423\n",
       "gimnasio                     4763\n",
       "estrenar                     4394\n",
       "lujoso                       4275\n",
       "vista                        3850\n",
       "subte-linea-d                3639\n",
       "quincho                      3599\n",
       "hidromasaje                  3170\n",
       "subte-linea-b                2986\n",
       "subte-linea-a                2541\n",
       "impecable                    2402\n",
       "ph                           2351\n",
       "losa-radiante                2123\n",
       "nordelta                     2115\n",
       "apto-credito-hipotecario     2093\n",
       "tigre                        1989\n",
       "subte-linea-h                1960\n",
       "belgrano                     1819\n",
       "sauna                        1760\n",
       "palermo                      1656\n",
       "caballito                    1540\n",
       "subte-linea-e                1458\n",
       "amoblado                     1353\n",
       "pilar                        1327\n",
       "tenis                        1250\n",
       "subte-linea-c                1152\n",
       "barrio-norte                 1021\n",
       "villa-urquiza                 983\n",
       "olivos                        936\n",
       "villa-crespo                  914\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fracciono la columna properti_url para sacar la nube de palabras mas repetidas\n",
    "patron_url = re.compile(pattern = \"_\", flags = re.IGNORECASE)\n",
    "lista_url = data_na[\"properati_url\"].apply(lambda x : patron_url.split(x))\n",
    "serie_palabras = pd.Series(np.hstack(lista_url))\n",
    "#serie_palabras.value_counts().head(20).plot(kind=\"bar\")\n",
    "serie_palabras.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Jk22xPJZa9pm"
   },
   "outputs": [],
   "source": [
    "# a partir de la nube de palabras selecciono las que son buenos adicionales\n",
    "adicionales = [\"garage\", \"balcon\", \"parrilla\", \"piscina\", \"terraza\", \"patio\", \"jardin\", \"quincho\", \"sum\", \"amenities\", \"baulera\", \"gimnasio\", \"subte-linea-d\", \"subte-linea-b\", \"subte-linea-a\", \"subte-linea-h\", \"subte-linea-e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cSivTSfQoiyj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [venta, ph, mataderos, lavadero, patio, inmobi...\n",
       "2         [venta, departamentos, mataderos, lavadero, pl...\n",
       "6         [venta, ph, munro, lavadero, patio, garage, al...\n",
       "7         [venta, departamentos, belgrano, lavadero, pis...\n",
       "8         [venta, departamentos, belgrano, lavadero, pis...\n",
       "                                ...                        \n",
       "121154    [venta, casa, la-plata, suite, parrilla, pisci...\n",
       "121158    [venta, departamento, recoleta, pueyrredon-av-...\n",
       "121215    [venta, departamento, belgrano, balcon, suite,...\n",
       "121216    [venta, casa, beccar, suite, hidromasaje, jard...\n",
       "121217    [venta, departamento, villa-urquiza, holmberg,...\n",
       "Name: properati_url, Length: 42717, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elimino el primer elemento de lista_url para no tener el elemento con el http: etc\n",
    "for sublist in lista_url:\n",
    "  del sublist[0]\n",
    "\n",
    "lista_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6xTQyApPl1_c"
   },
   "outputs": [],
   "source": [
    "#creo una función que compare la lista de palabras con la lista de listas\n",
    "#y me da como resultado una lista de listas de palabras true/false segun coincida o no \n",
    "def buscador_palabras(quebuscar, dondebuscar):\n",
    "  listadeextras = []\n",
    "  for listas in dondebuscar:\n",
    "    extras = []\n",
    "    for palabra in quebuscar:\n",
    "      if palabra in listas:\n",
    "        extras.append(True)\n",
    "      else:\n",
    "        extras.append(False)\n",
    "    listadeextras.append(extras)\n",
    "  #print(listadeextras)\n",
    "  return listadeextras     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1651431280900,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "QKvkph_HnmMP",
    "outputId": "694bb379-1473-4e3a-dc79-a905264d2952"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42717"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aplico la funcion a mi lista \"adicionales\" y \"lista_url\"\n",
    "#chequeo que tenga la misma longitud de data\n",
    "resultado = buscador_palabras(adicionales, lista_url)\n",
    "len(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1651431280900,
     "user": {
      "displayName": "Maela Lombardi",
      "userId": "03936068368896012188"
     },
     "user_tz": 180
    },
    "id": "nE4L2iH5i1-4",
    "outputId": "90fcc17a-7268-4b64-b061-87b4f7263271"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am_garage</th>\n",
       "      <th>am_balcon</th>\n",
       "      <th>am_parrilla</th>\n",
       "      <th>am_piscina</th>\n",
       "      <th>am_terraza</th>\n",
       "      <th>am_patio</th>\n",
       "      <th>am_jardin</th>\n",
       "      <th>am_quincho</th>\n",
       "      <th>am_s.u.m.</th>\n",
       "      <th>am_amenities</th>\n",
       "      <th>am_baulera</th>\n",
       "      <th>am_gimnasio</th>\n",
       "      <th>am_subte-linea-d</th>\n",
       "      <th>am_subte-linea-b</th>\n",
       "      <th>am_subte-linea-a</th>\n",
       "      <th>am_subte-linea-h</th>\n",
       "      <th>am_subte-linea-e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42712</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42713</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42714</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42715</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42716</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42717 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       am_garage  am_balcon  am_parrilla  am_piscina  am_terraza  am_patio  \\\n",
       "0          False      False        False       False       False      True   \n",
       "1          False      False        False       False       False     False   \n",
       "2           True      False        False       False       False      True   \n",
       "3          False      False        False        True       False     False   \n",
       "4          False      False        False        True       False     False   \n",
       "...          ...        ...          ...         ...         ...       ...   \n",
       "42712      False      False         True        True       False     False   \n",
       "42713      False       True         True       False       False     False   \n",
       "42714       True       True         True        True       False     False   \n",
       "42715       True      False         True        True       False     False   \n",
       "42716       True       True         True       False        True     False   \n",
       "\n",
       "       am_jardin  am_quincho  am_s.u.m.  am_amenities  am_baulera  \\\n",
       "0          False       False      False         False       False   \n",
       "1          False       False      False         False       False   \n",
       "2          False       False      False         False       False   \n",
       "3          False       False      False         False       False   \n",
       "4          False       False      False         False       False   \n",
       "...          ...         ...        ...           ...         ...   \n",
       "42712      False       False      False         False       False   \n",
       "42713      False       False      False         False       False   \n",
       "42714      False        True      False         False       False   \n",
       "42715       True        True      False         False       False   \n",
       "42716      False       False      False          True       False   \n",
       "\n",
       "       am_gimnasio  am_subte-linea-d  am_subte-linea-b  am_subte-linea-a  \\\n",
       "0            False             False             False             False   \n",
       "1            False             False             False             False   \n",
       "2            False             False             False             False   \n",
       "3            False             False             False             False   \n",
       "4            False             False             False             False   \n",
       "...            ...               ...               ...               ...   \n",
       "42712        False             False             False             False   \n",
       "42713        False             False             False             False   \n",
       "42714        False             False             False             False   \n",
       "42715        False             False             False             False   \n",
       "42716        False             False             False             False   \n",
       "\n",
       "       am_subte-linea-h  am_subte-linea-e  \n",
       "0                 False             False  \n",
       "1                 False             False  \n",
       "2                 False             False  \n",
       "3                 False             False  \n",
       "4                 False             False  \n",
       "...                 ...               ...  \n",
       "42712             False             False  \n",
       "42713              True             False  \n",
       "42714             False             False  \n",
       "42715             False             False  \n",
       "42716             False             False  \n",
       "\n",
       "[42717 rows x 17 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convierto resultado en dataframe, y renombro las columnas por la lista de palabras adicionales\n",
    "df = pd.DataFrame(resultado)\n",
    "df.columns = [\"garage\", \"balcon\", \"parrilla\", \"piscina\", \"terraza\", \"patio\", \"jardin\", \"quincho\", \"s.u.m.\", \"amenities\", \"baulera\", \"gimnasio\",\"subte-linea-d\", \"subte-linea-b\", \"subte-linea-a\", \"subte-linea-h\", \"subte-linea-e\"]\n",
    "df = df.add_prefix('am_')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DHZhUj4uxYJA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'state_name', 'place_name', 'place_with_parent_names',\n",
       "       'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
       "       'price_usd_per_m2', 'rooms', 'description', 'title', 'properati_url',\n",
       "       'am_garage', 'am_balcon', 'am_parrilla', 'am_piscina', 'am_terraza',\n",
       "       'am_patio', 'am_jardin', 'am_quincho', 'am_s.u.m.', 'am_amenities',\n",
       "       'am_baulera', 'am_gimnasio', 'am_subte-linea-d', 'am_subte-linea-b',\n",
       "       'am_subte-linea-a', 'am_subte-linea-h', 'am_subte-linea-e'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42717, 29)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uno el dataframe original con el nuevo generado de true/false\n",
    "#data = pd.merge(data,df,left_index=True, right_index=True)\n",
    "data_dum_1 = data_na.join(df)\n",
    "data_dum_1.columns\n",
    "#antes me puso los dos indices como resultado del merge, y tuve que sacar la primera columna\n",
    "#data.drop(columns=data.columns[0], axis=1,inplace=True)\n",
    "data_dum_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "f452ad15"
   },
   "source": [
    "### 3.3.2. *State name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creé las dummies sin drop_first para poder hacer el join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sn = pd.get_dummies(data_dum_1[\"state_name\"], prefix = 'sn', drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'state_name', 'place_name', 'place_with_parent_names',\n",
       "       'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
       "       'price_usd_per_m2', 'rooms', 'description', 'title', 'properati_url',\n",
       "       'am_garage', 'am_balcon', 'am_parrilla', 'am_piscina', 'am_terraza',\n",
       "       'am_patio', 'am_jardin', 'am_quincho', 'am_s.u.m.', 'am_amenities',\n",
       "       'am_baulera', 'am_gimnasio', 'am_subte-linea-d', 'am_subte-linea-b',\n",
       "       'am_subte-linea-a', 'am_subte-linea-h', 'am_subte-linea-e',\n",
       "       'sn_Bs.As. G.B.A. Zona Oeste', 'sn_Bs.As. G.B.A. Zona Sur',\n",
       "       'sn_Capital Federal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42717, 32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dum_2 = data_dum_1.join(df_sn)\n",
    "data_dum_2.columns\n",
    "data_dum_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### 3.3.3. *Property type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt = pd.get_dummies(data_dum_2[\"property_type\"], prefix = 'pt', drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'state_name', 'place_name', 'place_with_parent_names',\n",
       "       'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
       "       'price_usd_per_m2', 'rooms', 'description', 'title', 'properati_url',\n",
       "       'am_garage', 'am_balcon', 'am_parrilla', 'am_piscina', 'am_terraza',\n",
       "       'am_patio', 'am_jardin', 'am_quincho', 'am_s.u.m.', 'am_amenities',\n",
       "       'am_baulera', 'am_gimnasio', 'am_subte-linea-d', 'am_subte-linea-b',\n",
       "       'am_subte-linea-a', 'am_subte-linea-h', 'am_subte-linea-e',\n",
       "       'sn_Bs.As. G.B.A. Zona Oeste', 'sn_Bs.As. G.B.A. Zona Sur',\n",
       "       'sn_Capital Federal', 'pt_apartment', 'pt_house', 'pt_store'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42717, 35)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dum_3 = data_dum_2.join(df_pt)\n",
    "data_dum_3.columns\n",
    "data_dum_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### 3.3.4. *Place name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creé las dummies sin drop_first para poder hacer el join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pn = pd.get_dummies(data_dum_3[\"place_name\"], prefix = \"pn\", drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type', 'state_name', 'place_name', 'place_with_parent_names',\n",
       "       'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
       "       'price_usd_per_m2', 'rooms', 'description',\n",
       "       ...\n",
       "       'pn_Villa de Mayo', 'pn_Villa del Parque',\n",
       "       'pn_Village Golf & Tennis Country Club', 'pn_Virasoro Village',\n",
       "       'pn_Virrey del Pino', 'pn_Virreyes', 'pn_Wilde', 'pn_William Morris',\n",
       "       'pn_Zelaya', 'pn_coordenadas 34.255511'],\n",
       "      dtype='object', length=485)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42717, 485)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dum_4 = data_dum_3.join(df_pn)\n",
    "data_dum_4.columns\n",
    "data_dum_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### 3.3.5. Dropeo de columnas innecesarias y una de cada *dummy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42717, 478)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['price_aprox_usd',\n",
       " 'surface_total_in_m2',\n",
       " 'surface_covered_in_m2',\n",
       " 'price_usd_per_m2',\n",
       " 'rooms',\n",
       " 'am_garage',\n",
       " 'am_balcon',\n",
       " 'am_parrilla',\n",
       " 'am_piscina',\n",
       " 'am_terraza',\n",
       " 'am_patio',\n",
       " 'am_jardin',\n",
       " 'am_quincho',\n",
       " 'am_s.u.m.',\n",
       " 'am_amenities',\n",
       " 'am_baulera',\n",
       " 'am_gimnasio',\n",
       " 'am_subte-linea-d',\n",
       " 'am_subte-linea-b',\n",
       " 'am_subte-linea-a',\n",
       " 'am_subte-linea-h',\n",
       " 'am_subte-linea-e',\n",
       " 'sn_Bs.As. G.B.A. Zona Oeste',\n",
       " 'sn_Bs.As. G.B.A. Zona Sur',\n",
       " 'sn_Capital Federal',\n",
       " 'pt_apartment',\n",
       " 'pt_house',\n",
       " 'pt_store',\n",
       " 'pn_ los alamos',\n",
       " 'pn_9 de Abril',\n",
       " 'pn_Abasto',\n",
       " 'pn_Abril Club de Campo',\n",
       " 'pn_Acacias Blancas',\n",
       " 'pn_Acassuso',\n",
       " 'pn_Adrogué',\n",
       " 'pn_Aeropuerto Internacional Ezeiza',\n",
       " 'pn_Agronomía',\n",
       " 'pn_Albanueva Barrio Cerrado',\n",
       " 'pn_Aldo Bonzi',\n",
       " 'pn_Alejandro Korn',\n",
       " 'pn_Almagro',\n",
       " 'pn_Almirante Brown',\n",
       " 'pn_Altamira',\n",
       " 'pn_Altos de Hudson II',\n",
       " 'pn_Altos de Manzanares 1 y 2',\n",
       " 'pn_Altos de Matheu',\n",
       " 'pn_Altos del Golf',\n",
       " 'pn_Altos del Pilar',\n",
       " 'pn_Armenia Country Club',\n",
       " 'pn_Avellaneda',\n",
       " 'pn_Bahía del Sol',\n",
       " 'pn_Balvanera',\n",
       " 'pn_Banfield',\n",
       " 'pn_Barbarita, Barrio Cerrado',\n",
       " 'pn_Barracas',\n",
       " 'pn_Barrancas de San Jose',\n",
       " 'pn_Barrancas de Santa María',\n",
       " 'pn_Barrio Acacias',\n",
       " 'pn_Barrio Araucarias',\n",
       " 'pn_Barrio Cabos del Lago',\n",
       " 'pn_Barrio Cerrado \"Ayres Plaza\"',\n",
       " 'pn_Barrio Cerrado \"Buenos Aires Village\"',\n",
       " 'pn_Barrio Cerrado \"Isla del Sol\"',\n",
       " 'pn_Barrio Cerrado \"La Candelaria\"',\n",
       " 'pn_Barrio Cerrado \"La Cautiva del Pilar\"',\n",
       " 'pn_Barrio Cerrado \"La Damasia\"',\n",
       " 'pn_Barrio Cerrado \"La Delfina\"',\n",
       " 'pn_Barrio Cerrado \"La Montura\"',\n",
       " 'pn_Barrio Cerrado \"La Tranquera\"',\n",
       " 'pn_Barrio Cerrado \"Las Marías\"',\n",
       " 'pn_Barrio Cerrado \"Los Ombúes de Hudson\"',\n",
       " 'pn_Barrio Cerrado \"Los Potrillos\"',\n",
       " 'pn_Barrio Cerrado \"Los Senderos\"',\n",
       " 'pn_Barrio Cerrado \"Roble Joven\"',\n",
       " 'pn_Barrio Cerrado \"Soles de Pilar\"',\n",
       " 'pn_Barrio Cerrado \"SpringDale\"',\n",
       " 'pn_Barrio Cerrado \"Tres Horquetas\"',\n",
       " 'pn_Barrio Cerrado \"Villa Rosa\"',\n",
       " 'pn_Barrio Cerrado El Casco de Alvarez',\n",
       " 'pn_Barrio Cerrado El Lucero',\n",
       " 'pn_Barrio Cerrado Lagos del Norte',\n",
       " 'pn_Barrio Cerrado Las Casuarinas',\n",
       " 'pn_Barrio El Golf',\n",
       " 'pn_Barrio El Moro',\n",
       " 'pn_Barrio La Alameda',\n",
       " 'pn_Barrio La Cuesta',\n",
       " 'pn_Barrio La Isla',\n",
       " 'pn_Barrio Las Glorietas',\n",
       " 'pn_Barrio Los Alisos',\n",
       " 'pn_Barrio Los Castores',\n",
       " 'pn_Barrio Los Lagos',\n",
       " 'pn_Barrio Marinas',\n",
       " 'pn_Barrio Melazzi',\n",
       " 'pn_Barrio Norte',\n",
       " 'pn_Barrio Parque Almirante Irízar',\n",
       " 'pn_Barrio Parque General San Martin',\n",
       " 'pn_Barrio Parque San Martin',\n",
       " 'pn_Barrio Privado \"Lomas de Fátima\"',\n",
       " 'pn_Barrio Privado El Recodo  S.A.',\n",
       " 'pn_Barrio Privado El Rodal',\n",
       " 'pn_Barrio Privado Santa Rita',\n",
       " 'pn_Barrio San Agustin',\n",
       " 'pn_Barrio San Eduardo - Pilar del Este',\n",
       " 'pn_Barrio San Gabriel',\n",
       " 'pn_Barrio San Matías',\n",
       " 'pn_Barrio San Rafael',\n",
       " 'pn_Barrio Santa Clara',\n",
       " 'pn_Barrio Santa Teresa',\n",
       " 'pn_Barrio Vistas',\n",
       " 'pn_Barrio cerrado Santa Ana',\n",
       " 'pn_BarrioPortezuelo',\n",
       " 'pn_Beccar',\n",
       " 'pn_Belgrano',\n",
       " 'pn_Bella Vista',\n",
       " 'pn_Belén de Escobar',\n",
       " 'pn_Benavidez',\n",
       " 'pn_Benavidez Greens',\n",
       " 'pn_Berazategui',\n",
       " 'pn_Berazategui Oeste',\n",
       " 'pn_Bermudas Country Club',\n",
       " 'pn_Bernal',\n",
       " 'pn_Billinghurst',\n",
       " 'pn_Boat Center Barrio Cerrado',\n",
       " 'pn_Boca',\n",
       " 'pn_Boca Ratón',\n",
       " 'pn_Boedo',\n",
       " 'pn_Boulogne Sur Mer',\n",
       " 'pn_Brickland',\n",
       " 'pn_Bs.As. G.B.A. Zona Norte',\n",
       " 'pn_Bs.As. G.B.A. Zona Oeste',\n",
       " 'pn_Bs.As. G.B.A. Zona Sur',\n",
       " 'pn_Burzaco',\n",
       " 'pn_Caballito',\n",
       " 'pn_Campos de Álvarez',\n",
       " 'pn_Canning',\n",
       " 'pn_Capital Federal',\n",
       " 'pn_Carapachay',\n",
       " 'pn_Carlos Spegazzini',\n",
       " 'pn_Caseros',\n",
       " 'pn_Castelar',\n",
       " 'pn_Catalinas',\n",
       " 'pn_Cañuelas',\n",
       " 'pn_Centro / Microcentro',\n",
       " 'pn_Chacarita',\n",
       " 'pn_Chacras de La Trinidad',\n",
       " 'pn_City Bell',\n",
       " 'pn_Ciudad Evita',\n",
       " 'pn_Ciudad Jardín Lomas del Palomar',\n",
       " 'pn_Ciudadela',\n",
       " 'pn_Claypole',\n",
       " 'pn_Club El Carmen - Sector casas',\n",
       " 'pn_Club de Campo Pueyrredón',\n",
       " 'pn_Coghlan',\n",
       " 'pn_Colegiales',\n",
       " 'pn_Complejo de Barrios Privados La Magdalena',\n",
       " 'pn_Congreso',\n",
       " 'pn_Constitución',\n",
       " 'pn_Country Banco Provincia',\n",
       " 'pn_Country Club Aranjuez',\n",
       " 'pn_Country Club Las lajas',\n",
       " 'pn_Country Farm Club',\n",
       " 'pn_Country Maschwitz Privado',\n",
       " 'pn_Country Nuevo Quilmes',\n",
       " 'pn_Country Saint Thomas',\n",
       " 'pn_Country San Jorge Village',\n",
       " 'pn_Cruce Castelar',\n",
       " 'pn_Crucecita',\n",
       " 'pn_Cuartel V',\n",
       " 'pn_Del Viso',\n",
       " 'pn_Delta',\n",
       " 'pn_Derqui',\n",
       " 'pn_Dique Luján',\n",
       " 'pn_Dock Sud',\n",
       " 'pn_Domselaar',\n",
       " 'pn_Don Bosco',\n",
       " 'pn_Don Orione',\n",
       " 'pn_Don Torcuato',\n",
       " 'pn_Echeverría del Lago',\n",
       " 'pn_El Canton Barrio Puerto',\n",
       " 'pn_El Casco de Leloir',\n",
       " 'pn_El Cazador',\n",
       " 'pn_El Centauro',\n",
       " 'pn_El Encuentro',\n",
       " 'pn_El Molino',\n",
       " 'pn_El Nacional Club de Campo',\n",
       " 'pn_El Palomar',\n",
       " 'pn_El Pato',\n",
       " 'pn_El Rocío',\n",
       " 'pn_El Talar',\n",
       " 'pn_El Talar de Pacheco',\n",
       " 'pn_El Viejo Vivero',\n",
       " 'pn_El Zorzal',\n",
       " 'pn_Enyoi',\n",
       " 'pn_Escobar',\n",
       " 'pn_Estancias del Pilar',\n",
       " 'pn_Esteban Echeverría',\n",
       " 'pn_Etcheverry',\n",
       " 'pn_Ex La Ponderosa',\n",
       " 'pn_Ezeiza',\n",
       " 'pn_Ezpeleta',\n",
       " 'pn_Fincas de Hudson',\n",
       " 'pn_Fincas de Iraola',\n",
       " 'pn_Fincas de San Vicente',\n",
       " 'pn_Fincas del Lago',\n",
       " 'pn_Florencio Varela',\n",
       " 'pn_Flores',\n",
       " 'pn_Floresta',\n",
       " 'pn_Florida',\n",
       " 'pn_Florida Oeste',\n",
       " 'pn_Francisco Alvarez',\n",
       " 'pn_Fátima',\n",
       " 'pn_Galapagos Country Club',\n",
       " 'pn_Garín',\n",
       " 'pn_General Pacheco',\n",
       " 'pn_General Rodríguez',\n",
       " 'pn_General San Martín',\n",
       " 'pn_Gerli',\n",
       " 'pn_Glew',\n",
       " 'pn_Golf Club Argentino',\n",
       " \"pn_Golfer's Country Club\",\n",
       " 'pn_González Catán',\n",
       " 'pn_Grand Bell',\n",
       " 'pn_Grand Bourg',\n",
       " 'pn_GreenVille Polo & Resort',\n",
       " 'pn_Gregorio de Laferrere',\n",
       " 'pn_Guernica',\n",
       " 'pn_Hacoaj Barrio Cerrado',\n",
       " 'pn_Haedo',\n",
       " 'pn_Haras María Elena',\n",
       " 'pn_Haras María Victoria',\n",
       " 'pn_Haras San Pablo',\n",
       " 'pn_Haras Santa Maria',\n",
       " 'pn_Haras del Pilar - El Establo',\n",
       " 'pn_Haras del Pilar - La Caballeriza',\n",
       " 'pn_Haras del Pilar - Las Praderas 1 y 2',\n",
       " 'pn_Haras del Sol - Barrio Privado',\n",
       " 'pn_Haras del Sur I',\n",
       " 'pn_Highland Park Country Club',\n",
       " 'pn_Hindu Club',\n",
       " 'pn_Hurlingham',\n",
       " 'pn_Ingeniero Adolfo Sourdeaux',\n",
       " 'pn_Ingeniero Juan Allan',\n",
       " 'pn_Ingeniero Pablo Nogués',\n",
       " 'pn_Isidro Casanova',\n",
       " 'pn_Islas del Canal',\n",
       " 'pn_Ituzaingó',\n",
       " 'pn_Jose Leon Suarez',\n",
       " 'pn_Jose Marmol',\n",
       " 'pn_José C Paz',\n",
       " 'pn_José Ingenieros',\n",
       " 'pn_La Agustina',\n",
       " 'pn_La Angélica',\n",
       " 'pn_La Cesarina',\n",
       " 'pn_La Comarca',\n",
       " 'pn_La Herradura',\n",
       " 'pn_La Lomada de Pilar',\n",
       " 'pn_La Lonja',\n",
       " 'pn_La Lucila',\n",
       " 'pn_La Madrugada',\n",
       " 'pn_La Martinica',\n",
       " 'pn_La Matanza',\n",
       " 'pn_La Peregrina',\n",
       " 'pn_La Plata',\n",
       " 'pn_La Reja',\n",
       " 'pn_La Tablada',\n",
       " 'pn_La Unión',\n",
       " 'pn_La horqueta de Echeverría',\n",
       " 'pn_Laguna del Sol',\n",
       " 'pn_Lanús',\n",
       " 'pn_Lanús Este',\n",
       " 'pn_Lanús Oeste',\n",
       " 'pn_Las Cañitas',\n",
       " 'pn_Las Golondrinas',\n",
       " 'pn_Libertad',\n",
       " 'pn_Liniers',\n",
       " 'pn_Lisandro Olmos',\n",
       " 'pn_Llavallol',\n",
       " 'pn_Loma Hermosa',\n",
       " 'pn_Loma Verde',\n",
       " 'pn_Lomas de Zamora',\n",
       " 'pn_Lomas del Mirador',\n",
       " 'pn_Longchamps',\n",
       " 'pn_Los Angeles Village',\n",
       " 'pn_Los Horneros CC',\n",
       " 'pn_Los Hornos',\n",
       " 'pn_Los Lagartos Country Club',\n",
       " 'pn_Los Pilares - Barrio Privado',\n",
       " 'pn_Los Polvorines',\n",
       " 'pn_Los Robles de Maschwitz',\n",
       " 'pn_Los Sauces Country Club',\n",
       " 'pn_Los Tres Coniles',\n",
       " 'pn_Luis Guillón',\n",
       " 'pn_Malvinas Argentinas',\n",
       " 'pn_Manuel Alberti',\n",
       " 'pn_Manuel B Gonnet',\n",
       " 'pn_Manzanares',\n",
       " 'pn_Mapuche Country Club',\n",
       " 'pn_Maquinista Savio',\n",
       " 'pn_Marcos Paz',\n",
       " 'pn_Marinas Golf Barrio Cerrado',\n",
       " 'pn_Martindale Country Club',\n",
       " 'pn_Martín Coronado',\n",
       " 'pn_Martínez',\n",
       " 'pn_Maschwitz',\n",
       " 'pn_Mataderos',\n",
       " 'pn_Matheu',\n",
       " 'pn_Mayling Club de Campo',\n",
       " 'pn_Medal Country Club',\n",
       " 'pn_Melchor Romero',\n",
       " 'pn_Merlo',\n",
       " 'pn_Mi Refugio',\n",
       " 'pn_Ministro Rivadavia',\n",
       " 'pn_Miraflores Country Club',\n",
       " 'pn_Monserrat',\n",
       " 'pn_Monte Castro',\n",
       " 'pn_Monte Chingolo',\n",
       " 'pn_Monte Grande',\n",
       " 'pn_Moreno',\n",
       " 'pn_Morón',\n",
       " 'pn_Munro',\n",
       " 'pn_Muñiz',\n",
       " 'pn_Máximo Paz',\n",
       " 'pn_Nordelta',\n",
       " 'pn_Nuñez',\n",
       " 'pn_Olivos',\n",
       " 'pn_Olivos Golf Club',\n",
       " 'pn_Once',\n",
       " 'pn_Pablo Podestá',\n",
       " 'pn_Pacheco Golf Club',\n",
       " 'pn_Palermo',\n",
       " 'pn_Palermo Chico',\n",
       " 'pn_Palermo Hollywood',\n",
       " 'pn_Palermo Soho',\n",
       " 'pn_Palermo Viejo',\n",
       " 'pn_Parque Avellaneda',\n",
       " 'pn_Parque Centenario',\n",
       " 'pn_Parque Chacabuco',\n",
       " 'pn_Parque Chas',\n",
       " 'pn_Parque Leloir',\n",
       " 'pn_Parque Patricios',\n",
       " 'pn_Paso del Rey',\n",
       " 'pn_Paternal',\n",
       " 'pn_Pilar',\n",
       " 'pn_Pilar Golf Country Club',\n",
       " 'pn_Pilar Green Park',\n",
       " 'pn_Pilar Village',\n",
       " 'pn_Pilar del Lago',\n",
       " 'pn_Piñeiro',\n",
       " 'pn_Pompeya',\n",
       " 'pn_Pontevedra',\n",
       " 'pn_Prados del Oeste',\n",
       " 'pn_Presidente Perón',\n",
       " 'pn_Puerto Madero',\n",
       " 'pn_QBay Yacht',\n",
       " 'pn_Quilmes',\n",
       " 'pn_Rafael Calzada',\n",
       " 'pn_Rafael Castillo',\n",
       " 'pn_Ramos Mejía',\n",
       " 'pn_Ranelagh',\n",
       " 'pn_Recoleta',\n",
       " 'pn_Remedios de Escalada',\n",
       " 'pn_Retiro',\n",
       " 'pn_Ricardo Rojas',\n",
       " 'pn_Rincon',\n",
       " 'pn_Rincon Del Arca',\n",
       " 'pn_Rincón de Maschwitz',\n",
       " 'pn_Rincón de Milberg',\n",
       " 'pn_Rincón de la Costa',\n",
       " 'pn_Ringuelet',\n",
       " 'pn_Saavedra',\n",
       " 'pn_Saint Matthews',\n",
       " 'pn_San Alberto',\n",
       " 'pn_San Andres',\n",
       " 'pn_San Antonio De Padua',\n",
       " 'pn_San Carlos',\n",
       " 'pn_San Cristobal',\n",
       " 'pn_San Eliseo Country, Golf, Hotel & Spa',\n",
       " 'pn_San Fernando',\n",
       " 'pn_San Francisco Club de Campo',\n",
       " 'pn_San Francisco Solano',\n",
       " 'pn_San Isidro',\n",
       " 'pn_San Isidro Chico',\n",
       " 'pn_San Jose',\n",
       " 'pn_San José',\n",
       " 'pn_San Juan',\n",
       " 'pn_San Justo',\n",
       " 'pn_San Lorenzo',\n",
       " 'pn_San Lucas Village',\n",
       " 'pn_San Martín',\n",
       " 'pn_San Miguel',\n",
       " 'pn_San Miguel Oeste',\n",
       " 'pn_San Miguel de Ghiso',\n",
       " 'pn_San Nicolás',\n",
       " 'pn_San Telmo',\n",
       " 'pn_San Vicente',\n",
       " 'pn_Santa Barbara Barrio Cerrado',\n",
       " 'pn_Santa Isabel',\n",
       " 'pn_Santa María de los Olivos',\n",
       " 'pn_Santa-Catalina',\n",
       " 'pn_Santos Lugares',\n",
       " 'pn_Sarandi',\n",
       " 'pn_Septiembre',\n",
       " 'pn_Solar del Bosque',\n",
       " 'pn_Solares del Talar',\n",
       " 'pn_Sourigues',\n",
       " 'pn_St. Patrick Country',\n",
       " 'pn_Sáenz Peña',\n",
       " 'pn_Talar del Lago 1',\n",
       " 'pn_Talar del lago 2',\n",
       " 'pn_Tapiales',\n",
       " 'pn_Temperley',\n",
       " 'pn_Terralagos',\n",
       " 'pn_Terravista Barrio Privado',\n",
       " 'pn_Tigre',\n",
       " 'pn_Tolosa',\n",
       " 'pn_Tortuguitas',\n",
       " 'pn_Tres de Febrero',\n",
       " 'pn_Tribunales',\n",
       " 'pn_Tristán Suárez',\n",
       " 'pn_Troncos del Talar',\n",
       " 'pn_Trujui',\n",
       " 'pn_Turdera',\n",
       " 'pn_Valentín Alsina',\n",
       " 'pn_Valle Claro',\n",
       " 'pn_Velez Sarsfield',\n",
       " 'pn_Versalles',\n",
       " 'pn_Vicente Casares',\n",
       " 'pn_Vicente López',\n",
       " 'pn_Victoria',\n",
       " 'pn_Villa Adelina',\n",
       " 'pn_Villa Ariza',\n",
       " 'pn_Villa Astolfi',\n",
       " 'pn_Villa Ballester',\n",
       " 'pn_Villa Bertha',\n",
       " 'pn_Villa Bonich',\n",
       " 'pn_Villa Bosch',\n",
       " 'pn_Villa Celina',\n",
       " 'pn_Villa Crespo',\n",
       " 'pn_Villa Devoto',\n",
       " 'pn_Villa Dominico',\n",
       " 'pn_Villa Elisa',\n",
       " 'pn_Villa Elvira',\n",
       " 'pn_Villa Fiorito',\n",
       " 'pn_Villa General Mitre',\n",
       " 'pn_Villa Granaderos De San Martin',\n",
       " 'pn_Villa Libertad',\n",
       " 'pn_Villa Lugano',\n",
       " 'pn_Villa Luro',\n",
       " 'pn_Villa Luzuriaga',\n",
       " 'pn_Villa Lynch',\n",
       " 'pn_Villa Madero',\n",
       " 'pn_Villa Maipu',\n",
       " 'pn_Villa Martelli',\n",
       " 'pn_Villa Monteagudo',\n",
       " 'pn_Villa Ortuzar',\n",
       " 'pn_Villa Pacheco',\n",
       " 'pn_Villa Pueyrredón',\n",
       " 'pn_Villa Raffo',\n",
       " 'pn_Villa Real',\n",
       " 'pn_Villa Riachuelo',\n",
       " 'pn_Villa Rosa',\n",
       " 'pn_Villa Santa Rita',\n",
       " 'pn_Villa Sarmiento',\n",
       " 'pn_Villa Soldati',\n",
       " 'pn_Villa Tesei',\n",
       " 'pn_Villa Udaondo',\n",
       " 'pn_Villa Urquiza',\n",
       " 'pn_Villa Vatteone',\n",
       " 'pn_Villa de Mayo',\n",
       " 'pn_Villa del Parque',\n",
       " 'pn_Village Golf & Tennis Country Club',\n",
       " 'pn_Virasoro Village',\n",
       " 'pn_Virrey del Pino',\n",
       " 'pn_Virreyes',\n",
       " 'pn_Wilde',\n",
       " 'pn_William Morris',\n",
       " 'pn_Zelaya',\n",
       " 'pn_coordenadas 34.255511']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <th>rooms</th>\n",
       "      <th>am_garage</th>\n",
       "      <th>am_balcon</th>\n",
       "      <th>am_parrilla</th>\n",
       "      <th>am_piscina</th>\n",
       "      <th>am_terraza</th>\n",
       "      <th>...</th>\n",
       "      <th>pn_Villa de Mayo</th>\n",
       "      <th>pn_Villa del Parque</th>\n",
       "      <th>pn_Village Golf &amp; Tennis Country Club</th>\n",
       "      <th>pn_Virasoro Village</th>\n",
       "      <th>pn_Virrey del Pino</th>\n",
       "      <th>pn_Virreyes</th>\n",
       "      <th>pn_Wilde</th>\n",
       "      <th>pn_William Morris</th>\n",
       "      <th>pn_Zelaya</th>\n",
       "      <th>pn_coordenadas 34.255511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62000.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1127.272727</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1309.090909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>130000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1226.415094</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>138000.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3066.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>195000.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_aprox_usd  surface_total_in_m2  surface_covered_in_m2  \\\n",
       "0          62000.0                 55.0                   40.0   \n",
       "2          72000.0                 55.0                   55.0   \n",
       "6         130000.0                106.0                   78.0   \n",
       "7         138000.0                 45.0                   40.0   \n",
       "8         195000.0                 65.0                   60.0   \n",
       "\n",
       "   price_usd_per_m2  rooms  am_garage  am_balcon  am_parrilla  am_piscina  \\\n",
       "0       1127.272727    2.0        0.0        0.0          0.0         0.0   \n",
       "2       1309.090909    2.0        1.0        0.0          0.0         0.0   \n",
       "6       1226.415094    2.0        0.0        0.0          0.0         1.0   \n",
       "7       3066.666667    1.0        0.0        0.0          0.0         1.0   \n",
       "8       3000.000000    2.0        0.0        0.0          1.0         0.0   \n",
       "\n",
       "   am_terraza  ...  pn_Villa de Mayo  pn_Villa del Parque  \\\n",
       "0         0.0  ...                 0                    0   \n",
       "2         0.0  ...                 0                    0   \n",
       "6         1.0  ...                 0                    0   \n",
       "7         0.0  ...                 0                    0   \n",
       "8         0.0  ...                 0                    0   \n",
       "\n",
       "   pn_Village Golf & Tennis Country Club  pn_Virasoro Village  \\\n",
       "0                                      0                    0   \n",
       "2                                      0                    0   \n",
       "6                                      0                    0   \n",
       "7                                      0                    0   \n",
       "8                                      0                    0   \n",
       "\n",
       "   pn_Virrey del Pino  pn_Virreyes  pn_Wilde  pn_William Morris  pn_Zelaya  \\\n",
       "0                   0            0         0                  0          0   \n",
       "2                   0            0         0                  0          0   \n",
       "6                   0            0         0                  0          0   \n",
       "7                   0            0         0                  0          0   \n",
       "8                   0            0         0                  0          0   \n",
       "\n",
       "   pn_coordenadas 34.255511  \n",
       "0                         0  \n",
       "2                         0  \n",
       "6                         0  \n",
       "7                         0  \n",
       "8                         0  \n",
       "\n",
       "[5 rows x 478 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_dum_4.drop(columns = ['property_type', 'state_name', 'place_name', 'place_with_parent_names', 'description', 'title', 'properati_url'])\n",
    "bool_mapper = {False: 0, True: 1}\n",
    "data.replace(bool_mapper, inplace = True)\n",
    "data.shape\n",
    "list(data.columns)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# **4. Exportación del dataset resultante a un nuevo *.csv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "32391447"
   },
   "outputs": [],
   "source": [
    "# para exportar resultados\n",
    "data.to_csv(r'../data/properatti_tp2.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para usar el nuevo dataset desde el archivo\n",
    "# data = pd.read_csv(\"../data/properatti_tp2.csv\", sep = \",\", low_memory=False) \n",
    "# data.head(3)\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRPdpsNHCvvO"
   },
   "source": [
    "# **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec_ZZaiACvvP"
   },
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tard3cPMCvvP"
   },
   "outputs": [],
   "source": [
    "# Definimos parámetros globales para matplotlib.\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwKUBHpMCvvP"
   },
   "outputs": [],
   "source": [
    "# importamos el modelo lineal y algunas funciones para calcular la bondad de ajuste.\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3mYbwJ2CvvP"
   },
   "outputs": [],
   "source": [
    "# Seleccionamos la variable predictora y la objetivo.\n",
    "X = df[[features]]\n",
    "y = targets[target]\n",
    "\n",
    "# Importamos, Instanciamos, Fiteamos, etc..\n",
    "\n",
    "# Instanciamos el modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Fiteamos el modelo sobre los vectores X e y.\n",
    "model = lm.fit(X, y)\n",
    "#\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', model.intercept_)\n",
    "print ('RM=', ' ', model.coef_)\n",
    "# imprimos la metrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2_train=', ' ', model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTps1hBOCvvP"
   },
   "outputs": [],
   "source": [
    "# Generamos una función que resume los coeficientes, el intercepto y el R2\n",
    "# \"model\" = objeto con el modelo\n",
    "# \"X\" = matrix de variables independientes\n",
    "\n",
    "def sum_mod(model, X):\n",
    "    a = pd.DataFrame(model.coef_ , X.columns.values)\n",
    "    a = a.append(pd.DataFrame([model.intercept_, model.score(X, y)], index=['Intecept','R2']))\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGk0KyfLCvvQ"
   },
   "outputs": [],
   "source": [
    "# Graficamos el modelo\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando (una, dos, todas) las variables\")\n",
    "plt.ylabel(\"Valores reales \")\n",
    "plt.show()\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (\"¿Mejora?: \", mean_squared_error(y, predictions) < prevMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcTAPLkpCvvQ"
   },
   "source": [
    "## Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGhJ8EZdCvvQ"
   },
   "outputs": [],
   "source": [
    "# Importamos la api.\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# De manera análoga a la vista en el primer ejercicio, definimos el vector de variables con la primer variable RM.\n",
    "X = df[[features]]\n",
    "y = df[[target]]\n",
    "\n",
    "# Tenemos que agregar explícitamente a una constante:\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.plot(y,y, '-.', c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones\")\n",
    "plt.ylabel(\"Valores reales target\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos el MSE y un resumen del modelo\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZyZhrTXCvvQ"
   },
   "outputs": [],
   "source": [
    "#para CLMultiple\n",
    "# visualizamos la matriz de correlación en Seaborn usando a heatmap\n",
    "\n",
    "sns.heatmap(bikes.corr(), vmin=-1, vmax=1, center=0, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kEnZ3dwCvvQ"
   },
   "outputs": [],
   "source": [
    "#elegir entre modelos\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print ('MAE:', metrics.mean_absolute_error(true, pred))\n",
    "print ('MSE:', metrics.mean_squared_error(true, pred))\n",
    "print ('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))\n",
    "print ('R2:', metrics.r2_score(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBFo9QtbCvvR"
   },
   "outputs": [],
   "source": [
    "# Definimos una función que acepta una lista de features, hace el split entre train y test,\n",
    "# reservando un 25% de las observaciones para testeo, y devuelve la prueba RMSE.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_rmse(feature_cols):\n",
    "    X = bikes[feature_cols]\n",
    "    y = bikes.total\n",
    "    # Como estamos trabajando con observaciones ordenadas en el tiempo, ponemos\n",
    "    # shuffle=False para evitar data leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0O8JvaGCvvR"
   },
   "outputs": [],
   "source": [
    "# Chequeamos que las columnas son perfectamente dependientes.\n",
    "np.all(bikes.casual + bikes.registered == bikes.total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nP6rUc2JCvvR"
   },
   "source": [
    "## Compruebo los supuestos Gauss Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9zxDOc4CvvR"
   },
   "outputs": [],
   "source": [
    "#linearidad del modelo\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.api as sms\n",
    "sns.set_style('darkgrid')\n",
    "sns.mpl.rcParams['figure.figsize'] = (15.0, 9.0)\n",
    "\n",
    "def linearity_test(model, y):\n",
    "    '''\n",
    "    funcion para visualizar e identificar supuestos de linealidad sobre la regression lineal\n",
    "    \n",
    "    Args:\n",
    "    * model - fitted OLS model from statsmodels\n",
    "    * y - observed values\n",
    "    '''\n",
    "    fitted_vals = model.predict()\n",
    "    resids = model.resid\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    \n",
    "    sns.regplot(x=fitted_vals, y=y, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n",
    "    ax[0].set_title('Observados vs. Valores Predichos', fontsize=16)\n",
    "    ax[0].set(xlabel='Predichos', ylabel='Observados')\n",
    "\n",
    "    sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[1], line_kws={'color': 'red'})\n",
    "    ax[1].set_title('Residos vs. Valores Predichos', fontsize=16)\n",
    "    ax[1].set(xlabel='Predichos', ylabel='Residuos')\n",
    "    \n",
    "linearity_test(lin_reg, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWw9TyFrCvvR"
   },
   "outputs": [],
   "source": [
    "#media de los residuos\n",
    "lin_reg.resid.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_TmQS41CvvR"
   },
   "outputs": [],
   "source": [
    "#multicolinearidad uso IVF(inflación de varianza) muestra cuánto más grande es el error estándar, en comparación \n",
    "#con lo que sería si ese predictor no estuviera correlacionado con las otras características del modelo . \n",
    "#Si no se correlacionan características, todos los valores para VIF serán 1.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\n",
    "pd.DataFrame({'vif': vif[1:]}, index=X.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5_qVAOOCvvR"
   },
   "outputs": [],
   "source": [
    "#homocedasticidad\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.api as sms\n",
    "sns.set_style('darkgrid')\n",
    "sns.mpl.rcParams['figure.figsize'] = (15.0, 9.0)\n",
    "\n",
    "def homoscedasticity_test(model):\n",
    "    '''\n",
    "    Function for testing the homoscedasticity of residuals in a linear regression model.\n",
    "    It plots residuals and standardized residuals vs. fitted values and runs Breusch-Pagan and Goldfeld-Quandt tests.\n",
    "    \n",
    "    Args:\n",
    "    * model - fitted OLS model from statsmodels\n",
    "    '''\n",
    "    import numpy as np\n",
    "    fitted_vals = model.predict()\n",
    "    resids = model.resid\n",
    "    resids_standardized = model.get_influence().resid_studentized_internal\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "\n",
    "    sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n",
    "    ax[0].set_title('Residuals vs Fitted', fontsize=16)\n",
    "    ax[0].set(xlabel='Fitted Values', ylabel='Residuals')\n",
    "\n",
    "    sns.regplot(x=fitted_vals, y=np.sqrt(np.abs(resids_standardized)), lowess=True, ax=ax[1], line_kws={'color': 'red'})\n",
    "    ax[1].set_title('Scale-Location', fontsize=16)\n",
    "    ax[1].set(xlabel='Fitted Values', ylabel='sqrt(abs(Residuals))')\n",
    "\n",
    "    bp_test = pd.DataFrame(sms.het_breuschpagan(resids, model.model.exog), \n",
    "                           columns=['value'],\n",
    "                           index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n",
    "\n",
    "    gq_test = pd.DataFrame(sms.het_goldfeldquandt(resids, model.model.exog)[:-1],\n",
    "                           columns=['value'],\n",
    "                           index=['F statistic', 'p-value'])\n",
    "\n",
    "    print('\\n Breusch-Pagan test ----')\n",
    "    print(bp_test)\n",
    "    print('\\n Goldfeld-Quandt test ----')\n",
    "    print(gq_test)\n",
    "    print('\\n Residuals plots ----')\n",
    "\n",
    "homoscedasticity_test(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Df7kgBeHCvvS"
   },
   "outputs": [],
   "source": [
    "#autocorrelacion\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "acf = smt.graphics.plot_acf(lin_reg.resid, lags=40 , alpha=0.05)\n",
    "#acf.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYtoljvyCvvS"
   },
   "outputs": [],
   "source": [
    "#normalidad de los residuos\n",
    "from scipy import stats\n",
    "\n",
    "def normality_of_residuals_test(model):\n",
    "    '''\n",
    "    Function for drawing the normal QQ-plot of the residuals and running 4 statistical tests to \n",
    "    investigate the normality of residuals.\n",
    "    \n",
    "    Arg:\n",
    "    * model - fitted OLS models from statsmodels\n",
    "    '''\n",
    "    sm.ProbPlot(model.resid).qqplot(line='s');\n",
    "    plt.title('Q-Q plot');\n",
    "\n",
    "    jb = stats.jarque_bera(model.resid)\n",
    "    sw = stats.shapiro(model.resid)\n",
    "    ad = stats.anderson(model.resid, dist='norm')\n",
    "    ks = stats.kstest(model.resid, 'norm')\n",
    "    \n",
    "    print(f'Jarque-Bera test ---- statistic: {jb[0]:.4f}, p-value: {jb[1]}')\n",
    "    print(f'Shapiro-Wilk test ---- statistic: {sw[0]:.4f}, p-value: {sw[1]:.4f}')\n",
    "    print(f'Kolmogorov-Smirnov test ---- statistic: {ks.statistic:.4f}, p-value: {ks.pvalue:.4f}')\n",
    "    print(f'Anderson-Darling test ---- statistic: {ad.statistic:.4f}, 5% critical value: {ad.critical_values[2]:.4f}')\n",
    "    print('If the returned AD statistic is larger than the critical value, then for the 5% significance level, the null hypothesis that the data come from the Normal distribution should be rejected. ')\n",
    "    \n",
    "normality_of_residuals_test(lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "W1linq1NCvvS"
   },
   "source": [
    "## Variables dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNYhTGVnCvvS"
   },
   "outputs": [],
   "source": [
    "#pandas (drop_first para evitar la colinearidad perfecta)\n",
    "dummy = pd.get_dummies(df[column], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvXxLv1xCvvS"
   },
   "outputs": [],
   "source": [
    "#scikit onehotencoder\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "# fiteo y transformo la columna \"sex\"\n",
    "dummy_oneHot = onehot_encoder.fit_transform(df[['Sex']])\n",
    "# pongo un vector en un dataset.\n",
    "dummy_oneHot = pd.DataFrame(dummy_oneHot.toarray(),columns=df['Sex'].unique())\n",
    "dummy_oneHot.head()\n",
    "\n",
    "#con drop_first\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehot_encoder2 = OneHotEncoder(drop='first')\n",
    "# fiteo y transformo la columna \"sex\"\n",
    "dummy_oneHot_correct = onehot_encoder2.fit_transform(df[['Sex']])\n",
    "# pongo un vector en un dataset.\n",
    "dummy_oneHot_correct = pd.DataFrame(dummy_oneHot_correct.toarray())\n",
    "dummy_oneHot_correct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1UTv0-9CvvT"
   },
   "outputs": [],
   "source": [
    "#para variables categoricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(df['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o0t4azMCvvT"
   },
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-WsIM2-CvvT"
   },
   "outputs": [],
   "source": [
    "#metodo manual con mean y std\n",
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "plt.scatter(xs, ys, color='b')\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()\n",
    "\n",
    "xs = df[\"NOX\"]\n",
    "mean = np.mean(xs)\n",
    "std = np.std(xs)\n",
    "xs = [(x - mean) / std for x in xs]\n",
    "\n",
    "ys = df[\"TAX\"]\n",
    "mean = np.mean(ys)\n",
    "std = np.std(ys)\n",
    "ys = [(y - mean) / std for y in ys]\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX standardized\")\n",
    "plt.ylabel(\"TAX standardized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-kPHM--CvvT"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "xs = preprocessing.scale(df[\"NOX\"])\n",
    "ys = preprocessing.scale(df[\"TAX\"])\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX standardized\")\n",
    "plt.ylabel(\"TAX standardized\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1LJAlHsCvvT"
   },
   "outputs": [],
   "source": [
    "#manual min max\n",
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "plt.scatter(xs, ys, color='b')\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()\n",
    "\n",
    "xs = df[\"NOX\"]\n",
    "xmin = np.min(xs)\n",
    "xmax = np.max(xs)\n",
    "xs = [(x - xmin) / (xmax - xmin) for x in xs]\n",
    "\n",
    "ys = df[\"TAX\"]\n",
    "ymin = np.min(ys)\n",
    "ymax = np.max(ys)\n",
    "ys = [(y - ymin) / (ymax - ymin) for y in ys]\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX Min-Max Scaled\")\n",
    "plt.ylabel(\"TAX Min-Max Scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML77-t4VCvvU"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "xs = scaler.fit_transform(df[[\"NOX\"]])\n",
    "ys = scaler.fit_transform(df[[\"TAX\"]])\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX Min-Max Scaled\")\n",
    "plt.ylabel(\"TAX Min-Max Scaled\")\n",
    "plt.show()\n",
    "\n",
    "#o\n",
    "numericals = ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "\n",
    "X = data[numericals]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "std_numerical_data = scaler.transform(X)\n",
    "std_df = pd.DataFrame(std_numerical_data)\n",
    "std_df.columns = [i + '_std' for i in numericals]\n",
    "std_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axcWN-UFCvvU"
   },
   "source": [
    "## Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYJDnfN0CvvU"
   },
   "outputs": [],
   "source": [
    "rlm = linear_model.Ridge(alpha=0.5, normalize=True)\n",
    "\n",
    "# Ajustamos nuevamente, esta vez con regularizacion\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "\n",
    "ridge_model = rlm.fit(X, y)\n",
    "predictions = ridge_model.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "print (\"r^2:\", ridge_model.score(X, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnUiZ_KtCvvU"
   },
   "outputs": [],
   "source": [
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = ridge_model.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos#2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "\n",
    "print (\"r^2:\", ridge_model.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KCQH6mBCvvU"
   },
   "outputs": [],
   "source": [
    "# Veamos los coeficientes de la regresión Ridge:    \n",
    "ridge_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=0.5, normalize=True)\n",
    "\n",
    "# Ajustamos nuevamente, esta vez con regularizacion\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "lasso_model =lasso.fit(X, y)\n",
    "predictions = lasso_model.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "\n",
    "print (\"r^2:\", lasso_model.score(X, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = lasso_model.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos#2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "\n",
    "print (\"r^2:\", lasso_model.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos los coeficientes de la regresión Lasso:    \n",
    "lasso_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12380/2890942708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0melastic_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Ajustamos nuevamente, esta vez con regularizacion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvander\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "elastic_net = linear_model.ElasticNet(alpha=0.5, normalize=True)\n",
    "\n",
    "# Ajustamos nuevamente, esta vez con regularizacion\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "\n",
    "elastic_net.fit(X, y)\n",
    "predictions = elastic_net.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "\n",
    "print (\"r^2:\", elastic_net.score(X, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = elastic_net.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos#2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "print (\"r^2:\", elastic_net.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos los coeficientes de la regresión ElasticNet:\n",
    "elastic_net.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Optimizacion de lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciamos un modelo \n",
    "rlmcv = linear_model.RidgeCV(alphas=np.linspace(0.1,100, 1000), cv=3, normalize=True,scoring='r2')\n",
    "\n",
    "\n",
    "# Ajustamos nuevamente nuestro modelo, esta vez con RidgeCV\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "rlmcv.fit(X, y)\n",
    "predictions = rlmcv.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "plt.show()\n",
    "print (\"r^2:\", rlmcv.score(X, ys))\n",
    "print (\"alpha:\", rlmcv.alpha_)\n",
    "\n",
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = rlmcv.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos #2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "plt.show()\n",
    "print (\"r^2:\", rlmcv.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = linear_model.LassoCV(alphas=np.linspace(0.01,100, 1000), cv=3, normalize=True)\n",
    "xs, ys = generate_data()\n",
    "\n",
    "\n",
    "# Ajustamos nuevamente nuestro modelo, esta vez con LassoCV\n",
    "X = np.vander(xs, 4)[:,:-1]\n",
    "y = ys\n",
    "lassocv.fit(X, y)\n",
    "predictions = lassocv.predict(X)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.title(\"Muestra de datos #1\")\n",
    "plt.scatter(xs, predictions, c='r')\n",
    "plt.show()\n",
    "print (\"r^2:\", lassocv.score(X, ys))\n",
    "print (\"alpha:\", lassocv.alpha_)\n",
    "\n",
    "X = np.vander(xs2, 4)[:,:-1]\n",
    "predictions = lassocv.predict(X)\n",
    "\n",
    "plt.scatter(xs2, ys2)\n",
    "plt.title(\"Muestra de datos #2\")\n",
    "plt.scatter(xs2, predictions, c='r')\n",
    "plt.show()\n",
    "print (\"r^2:\", lassocv.score(X, ys2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "lm_lasso = linear_model.LassoCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10],\\\n",
    "                                        normalize = False, cv = 5) \n",
    "\n",
    "model_cv = lm_lasso.fit(X_train, y_train)\n",
    "\n",
    "model_cv.score(X_train, y_train)\n",
    "\n",
    "model_cv.coef_\n",
    "model_cv.intercept_\n",
    "model_cv.alpha_\n",
    "model_cv.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = model_cv.alpha_\n",
    "\n",
    "#L1_wt : 0, the fit is ridge regression. 1, the fit is the lasso \n",
    "\n",
    "no_reg_model = sm.OLS(y_train, X_train_sm)\n",
    "\n",
    "reg_model = no_reg_model.fit_regularized(alpha = best_alpha, L1_wt = 1)\n",
    "\n",
    "reg_model.params\n",
    "sns.scatterplot(x=reg_model.params, y=no_reg_model_params);\n",
    "\n",
    "reg_residuals = y_train - reg_model.fittedvalues\n",
    "\n",
    "linear_residuals = y_train - model.fittedvalues\n",
    "\n",
    "sns.scatterplot(x = reg_residuals, y = linear_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_prediction = reg_model.predict(X_test_sm)\n",
    "sm_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_lasso = linear_model.Lasso(alpha = best_alpha, fit_intercept=True, normalize=False)\n",
    "\n",
    "skl_lasso = skl_lasso.fit(X= X_train, y = y_train)\n",
    "\n",
    "skl_prediction = skl_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_residuals = y_test - skl_prediction\n",
    "\n",
    "sm_residuals = y_test - sm_prediction\n",
    "\n",
    "sns.scatterplot(x = skl_residuals, y = sm_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lasso_coef = np.insert(skl_lasso.coef_, 0, skl_lasso.intercept_)\n",
    "\n",
    "sns.scatterplot(x = lasso_coef, y = reg_model.params);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_measures.rmse(y_test, sm_prediction)\n",
    "eval_measures.meanabs(y_test, sm_prediction)\n",
    "metrics.r2_score(y_test, sm_prediction)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, skl_prediction))\n",
    "metrics.mean_absolute_error(y_test, skl_prediction)\n",
    "metrics.r2_score(y_test, skl_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "540Z4u8bCvvU"
   },
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "  \n",
    "random.seed(3)\n",
    "boston = datasets.load_boston()\n",
    "y = boston.target\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "lr = linear_model.LinearRegression()\n",
    "cv = KFold(5, shuffle=True)\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=cv, scoring='r2')\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y85Atb2v2Fkr"
   },
   "outputs": [],
   "source": [
    "model = linear_model.LassoCV().fit(X_train, y_train)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean(), zero_coefs=(model.coef_ == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxyy6cem2Fkx"
   },
   "outputs": [],
   "source": [
    "model = linear_model.LassoCV(normalize=True).fit(X, y)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
    "dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean(), zero_coefs=(model.coef_ == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZoL46Vn2Fk5"
   },
   "outputs": [],
   "source": [
    "model = linear_model.RidgeCV(normalize=True).fit(X, y)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
    "dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqLgk68nRWHk"
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/salary.dat', delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZnFcPkBqRWH2"
   },
   "outputs": [],
   "source": [
    "# Aplicar value_counts() a las series \"sx\", \"dg\", and \"rk\"\n",
    "\n",
    "categories = ['sx', 'rk', 'dg']\n",
    "\n",
    "for category in categories:\n",
    "    print(df[category].value_counts())\n",
    "    plt.bar(df[category].value_counts().index, df[category].value_counts().values, color='b',\\\n",
    "            alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiT-3pSFRWH9"
   },
   "outputs": [],
   "source": [
    "# Hacer unos violinplots a las series \"sx\", \"dg\", and \"rk\"\n",
    "\n",
    "for category in categories:\n",
    "    sns.violinplot(x=category, y='sl', data=df)\n",
    "    plt.show()\n",
    "\n",
    "# Repetir para \"dg\" y \"rk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Y186sjORWIC"
   },
   "outputs": [],
   "source": [
    "# Crear variables \"dummy\"\n",
    "\n",
    "for category in categories:\n",
    "    serie = df[category]\n",
    "    dummies = pd.get_dummies(serie, drop_first= True, prefix=category)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo usando solamente las variables cuantitativas y MCO\n",
    "\n",
    "X = df[['yr', 'yd']]\n",
    "y = df['sl']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=10)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model_1 = lm.fit(X_train, y_train)\n",
    "\n",
    "print('Score model_1:', model_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo usando solamente las variables cuantitativas aplicando regularización\n",
    "#¿Hace falta normalizar los features antes aplicar regularización en este caso? ¿Qué unidades tienen los features?\n",
    "\n",
    "lm_ridge = linear_model.RidgeCV(alphas=[0.1, 1, 10], normalize=True) \n",
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "\n",
    "model_2 = lm_ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Score model_2:', model_2.score(X_test, y_test))\n",
    "\n",
    "# ¿Mejoraron los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con MCO:\n",
    "\n",
    "X_all = df.drop(['sx', 'rk', 'dg', 'sl'], axis=1) \n",
    "\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y, test_size=0.35, random_state=10)\n",
    "\n",
    "model_3 = lm.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_3:', model_3.score(X_all_test, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con Ridge:\n",
    "\n",
    "lm_ridge = linear_model.RidgeCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10],\\\n",
    "                                        normalize=True, cv=3) \n",
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "\n",
    "model_4 = lm_ridge.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_4:', model_4.score(X_all_test, y_all_test))\n",
    "\n",
    "# ¿Mejoraron los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_ridge.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con Lasso:\n",
    "\n",
    "lm_lasso = linear_model.LassoCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10, 15, 25],\\\n",
    "                                        normalize=True, cv=3)\n",
    "\n",
    "model_5 = lm_lasso.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_5:', model_5.score(X_all_test, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_lasso.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De articulo Comparacion Rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LINEAR, RIDGE AND LASSO REGRESSION\n",
    "'''\n",
    "# importing requuired libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "# read test and train file\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print('\\n\\n---------DATA---------------\\n\\n')\n",
    "print(train.head())\n",
    "\n",
    "#splitting into training and test\n",
    "## try building model with the different features and compare the result.\n",
    "X = train.loc[:,['Outlet_Establishment_Year','Item_MRP']]\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,train.Item_Outlet_Sales,random_state=5)\n",
    "\n",
    "print('--------Trainig Linear Regression Model---------------')\n",
    "lreg = LinearRegression()\n",
    "#training the model\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "#predicting on cv\n",
    "pred = lreg.predict(x_cv)\n",
    "\n",
    "#calculating mse\n",
    "mse = np.mean((pred - y_cv)**2)\n",
    "print('\\nMean Sqaured Error = ',mse )\n",
    "\n",
    "#Let us take a look at the coefficients of this linear regression model.\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "\n",
    "coeff['Coefficient Estimate'] = Series(lreg.coef_)\n",
    "\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(lreg.score(x_cv,y_cv))\n",
    "\n",
    "print('\\n\\n---------Training Ridge Regression Model----------------')\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(x_train,y_train)\n",
    "pred1 = ridge.predict(x_cv)\n",
    "mse_1 = np.mean((pred1-y_cv)**2)\n",
    "\n",
    "print('\\n\\nMean Squared Error = ',mse_1)\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "coeff['Coefficient Estimate'] = Series(ridge.coef_)\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(ridge.score(x_cv,y_cv))\n",
    "\n",
    "\n",
    "print('\\n\\n---------Training Lasso Regression Model----------------')\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(x_train,y_train)\n",
    "pred2 = lasso.predict(x_cv)\n",
    "mse_2 = np.mean((pred2-y_cv)**2)\n",
    "\n",
    "print('\\n\\nMean Squared Error = ',mse_2)\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "coeff['Coefficient Estimate'] = Series(lasso.coef_)\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(lasso.score(x_cv,y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHEYbgoQCvvU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RJTCe2C6wQOm",
    "E6SOCe17pdUo",
    "7EbzNZe_DThP",
    "4hxbVZ5SDJmF",
    "5us__nDgReat",
    "YtKfSxatXg7r",
    "ZI-vZGEyS6ez",
    "UCBAtlE9xZRo",
    "tXHPZXutaN0S"
   ],
   "name": "Maela.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "07ad563c6c100133d3911bd17dbe454dbfdab792a93b10a38a834bd0d63e4aeb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
